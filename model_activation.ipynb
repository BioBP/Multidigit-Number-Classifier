{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tuning activation function and compare\n",
    "#only use training set to do training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33402, 62)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training label\n",
    "labels = np.load('labels.npy')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 54, 54, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img as train data\n",
    "size = labels.shape[0]\n",
    "numsample = 5\n",
    "folder = 'train/croppedsampled/'\n",
    "images = []\n",
    "\n",
    "for k in range(numsample):\n",
    "    for i in range(size):\n",
    "        im = Image.open(folder+str(i+1)+'_'+str(k)+'.png')\n",
    "        images.append(np.asarray(im))\n",
    "        \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replicate labels to cover all sample\n",
    "labels = np.tile(labels,(5,1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split training set and validation set\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.1, random_state=0)\n",
    "train_index, test_index = next(rs.split(images)) #just 1\n",
    "test_images = images[test_index]\n",
    "test_labels = labels[test_index]\n",
    "images = images[train_index]\n",
    "labels = labels[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial model (same as initial model in other program)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/20\n",
      "135278/135278 [==============================] - 314s - loss: 5.7518 - dense_2_loss: 0.6318 - dense_3_loss: 1.8023 - dense_4_loss: 2.0212 - dense_5_loss: 0.9961 - dense_6_loss: 0.2168 - dense_7_loss: 0.0837 - val_loss: 3.6815 - val_dense_2_loss: 0.2836 - val_dense_3_loss: 1.1541 - val_dense_4_loss: 1.3667 - val_dense_5_loss: 0.7384 - val_dense_6_loss: 0.1372 - val_dense_7_loss: 0.0015\n",
      "Epoch 2/20\n",
      "135278/135278 [==============================] - 289s - loss: 3.3503 - dense_2_loss: 0.2717 - dense_3_loss: 1.0143 - dense_4_loss: 1.2177 - dense_5_loss: 0.6962 - dense_6_loss: 0.1467 - dense_7_loss: 0.0037 - val_loss: 2.5331 - val_dense_2_loss: 0.2103 - val_dense_3_loss: 0.7436 - val_dense_4_loss: 0.8995 - val_dense_5_loss: 0.5588 - val_dense_6_loss: 0.1197 - val_dense_7_loss: 0.0013\n",
      "Epoch 3/20\n",
      "135278/135278 [==============================] - 288s - loss: 2.4642 - dense_2_loss: 0.2053 - dense_3_loss: 0.7237 - dense_4_loss: 0.8566 - dense_5_loss: 0.5429 - dense_6_loss: 0.1316 - dense_7_loss: 0.0040 - val_loss: 1.8172 - val_dense_2_loss: 0.1515 - val_dense_3_loss: 0.5278 - val_dense_4_loss: 0.6134 - val_dense_5_loss: 0.4158 - val_dense_6_loss: 0.1072 - val_dense_7_loss: 0.0014\n",
      "Epoch 4/20\n",
      "135278/135278 [==============================] - 289s - loss: 2.0149 - dense_2_loss: 0.1718 - dense_3_loss: 0.5864 - dense_4_loss: 0.6823 - dense_5_loss: 0.4479 - dense_6_loss: 0.1223 - dense_7_loss: 0.0041 - val_loss: 1.5842 - val_dense_2_loss: 0.1373 - val_dense_3_loss: 0.4715 - val_dense_4_loss: 0.5326 - val_dense_5_loss: 0.3432 - val_dense_6_loss: 0.0978 - val_dense_7_loss: 0.0018\n",
      "Epoch 5/20\n",
      "135278/135278 [==============================] - 292s - loss: 1.7399 - dense_2_loss: 0.1495 - dense_3_loss: 0.5093 - dense_4_loss: 0.5794 - dense_5_loss: 0.3838 - dense_6_loss: 0.1137 - dense_7_loss: 0.0042 - val_loss: 1.4061 - val_dense_2_loss: 0.1400 - val_dense_3_loss: 0.4017 - val_dense_4_loss: 0.4585 - val_dense_5_loss: 0.3080 - val_dense_6_loss: 0.0960 - val_dense_7_loss: 0.0020\n",
      "Epoch 6/20\n",
      "135278/135278 [==============================] - 289s - loss: 1.5704 - dense_2_loss: 0.1357 - dense_3_loss: 0.4575 - dense_4_loss: 0.5197 - dense_5_loss: 0.3436 - dense_6_loss: 0.1095 - dense_7_loss: 0.0042 - val_loss: 1.2327 - val_dense_2_loss: 0.1205 - val_dense_3_loss: 0.3542 - val_dense_4_loss: 0.3990 - val_dense_5_loss: 0.2673 - val_dense_6_loss: 0.0896 - val_dense_7_loss: 0.0021\n",
      "Epoch 7/20\n",
      "135278/135278 [==============================] - 291s - loss: 1.4460 - dense_2_loss: 0.1278 - dense_3_loss: 0.4210 - dense_4_loss: 0.4722 - dense_5_loss: 0.3165 - dense_6_loss: 0.1042 - dense_7_loss: 0.0042 - val_loss: 1.2064 - val_dense_2_loss: 0.1087 - val_dense_3_loss: 0.3621 - val_dense_4_loss: 0.3834 - val_dense_5_loss: 0.2601 - val_dense_6_loss: 0.0899 - val_dense_7_loss: 0.0021\n",
      "Epoch 8/20\n",
      "135278/135278 [==============================] - 291s - loss: 1.3473 - dense_2_loss: 0.1175 - dense_3_loss: 0.3916 - dense_4_loss: 0.4399 - dense_5_loss: 0.2938 - dense_6_loss: 0.1002 - dense_7_loss: 0.0043 - val_loss: 1.0846 - val_dense_2_loss: 0.1033 - val_dense_3_loss: 0.3179 - val_dense_4_loss: 0.3394 - val_dense_5_loss: 0.2373 - val_dense_6_loss: 0.0846 - val_dense_7_loss: 0.0021\n",
      "Epoch 9/20\n",
      "135278/135278 [==============================] - 290s - loss: 1.2739 - dense_2_loss: 0.1116 - dense_3_loss: 0.3731 - dense_4_loss: 0.4106 - dense_5_loss: 0.2769 - dense_6_loss: 0.0973 - dense_7_loss: 0.0043 - val_loss: 1.0532 - val_dense_2_loss: 0.0990 - val_dense_3_loss: 0.3118 - val_dense_4_loss: 0.3324 - val_dense_5_loss: 0.2275 - val_dense_6_loss: 0.0803 - val_dense_7_loss: 0.0021\n",
      "Epoch 10/20\n",
      "135278/135278 [==============================] - 288s - loss: 1.2098 - dense_2_loss: 0.1056 - dense_3_loss: 0.3554 - dense_4_loss: 0.3886 - dense_5_loss: 0.2615 - dense_6_loss: 0.0945 - dense_7_loss: 0.0043 - val_loss: 1.0148 - val_dense_2_loss: 0.0971 - val_dense_3_loss: 0.2929 - val_dense_4_loss: 0.3227 - val_dense_5_loss: 0.2216 - val_dense_6_loss: 0.0783 - val_dense_7_loss: 0.0021\n",
      "Epoch 11/20\n",
      "135278/135278 [==============================] - 282s - loss: 1.1636 - dense_2_loss: 0.1013 - dense_3_loss: 0.3422 - dense_4_loss: 0.3738 - dense_5_loss: 0.2508 - dense_6_loss: 0.0913 - dense_7_loss: 0.0043 - val_loss: 1.0766 - val_dense_2_loss: 0.1110 - val_dense_3_loss: 0.3193 - val_dense_4_loss: 0.3327 - val_dense_5_loss: 0.2290 - val_dense_6_loss: 0.0825 - val_dense_7_loss: 0.0021\n",
      "Epoch 12/20\n",
      "135278/135278 [==============================] - 282s - loss: 1.1300 - dense_2_loss: 0.0986 - dense_3_loss: 0.3338 - dense_4_loss: 0.3614 - dense_5_loss: 0.2425 - dense_6_loss: 0.0895 - dense_7_loss: 0.0043 - val_loss: 0.9685 - val_dense_2_loss: 0.0933 - val_dense_3_loss: 0.2815 - val_dense_4_loss: 0.3019 - val_dense_5_loss: 0.2122 - val_dense_6_loss: 0.0775 - val_dense_7_loss: 0.0021\n",
      "Epoch 13/20\n",
      "135278/135278 [==============================] - 287s - loss: 1.0999 - dense_2_loss: 0.0972 - dense_3_loss: 0.3273 - dense_4_loss: 0.3484 - dense_5_loss: 0.2364 - dense_6_loss: 0.0863 - dense_7_loss: 0.0042 - val_loss: 0.9512 - val_dense_2_loss: 0.0955 - val_dense_3_loss: 0.2714 - val_dense_4_loss: 0.2935 - val_dense_5_loss: 0.2127 - val_dense_6_loss: 0.0761 - val_dense_7_loss: 0.0021\n",
      "Epoch 14/20\n",
      "135278/135278 [==============================] - 294s - loss: 1.0711 - dense_2_loss: 0.0942 - dense_3_loss: 0.3197 - dense_4_loss: 0.3403 - dense_5_loss: 0.2274 - dense_6_loss: 0.0852 - dense_7_loss: 0.0043 - val_loss: 0.9173 - val_dense_2_loss: 0.0859 - val_dense_3_loss: 0.2821 - val_dense_4_loss: 0.2812 - val_dense_5_loss: 0.1975 - val_dense_6_loss: 0.0685 - val_dense_7_loss: 0.0021\n",
      "Epoch 15/20\n",
      "135278/135278 [==============================] - 293s - loss: 1.0472 - dense_2_loss: 0.0943 - dense_3_loss: 0.3096 - dense_4_loss: 0.3310 - dense_5_loss: 0.2233 - dense_6_loss: 0.0848 - dense_7_loss: 0.0043 - val_loss: 0.9042 - val_dense_2_loss: 0.0887 - val_dense_3_loss: 0.2738 - val_dense_4_loss: 0.2779 - val_dense_5_loss: 0.1895 - val_dense_6_loss: 0.0722 - val_dense_7_loss: 0.0021\n",
      "Epoch 16/20\n",
      "135278/135278 [==============================] - 295s - loss: 1.0343 - dense_2_loss: 0.0938 - dense_3_loss: 0.3092 - dense_4_loss: 0.3245 - dense_5_loss: 0.2184 - dense_6_loss: 0.0843 - dense_7_loss: 0.0042 - val_loss: 0.9195 - val_dense_2_loss: 0.0873 - val_dense_3_loss: 0.2772 - val_dense_4_loss: 0.2891 - val_dense_5_loss: 0.1915 - val_dense_6_loss: 0.0723 - val_dense_7_loss: 0.0021\n",
      "Epoch 17/20\n",
      "135278/135278 [==============================] - 292s - loss: 1.0147 - dense_2_loss: 0.0900 - dense_3_loss: 0.3046 - dense_4_loss: 0.3204 - dense_5_loss: 0.2134 - dense_6_loss: 0.0822 - dense_7_loss: 0.0042 - val_loss: 0.8900 - val_dense_2_loss: 0.1007 - val_dense_3_loss: 0.2591 - val_dense_4_loss: 0.2635 - val_dense_5_loss: 0.1881 - val_dense_6_loss: 0.0765 - val_dense_7_loss: 0.0021\n",
      "Epoch 18/20\n",
      "135278/135278 [==============================] - 292s - loss: 1.0066 - dense_2_loss: 0.0899 - dense_3_loss: 0.3008 - dense_4_loss: 0.3148 - dense_5_loss: 0.2147 - dense_6_loss: 0.0822 - dense_7_loss: 0.0043 - val_loss: 0.8616 - val_dense_2_loss: 0.0852 - val_dense_3_loss: 0.2664 - val_dense_4_loss: 0.2575 - val_dense_5_loss: 0.1851 - val_dense_6_loss: 0.0654 - val_dense_7_loss: 0.0021\n",
      "Epoch 19/20\n",
      "135278/135278 [==============================] - 292s - loss: 0.9958 - dense_2_loss: 0.0895 - dense_3_loss: 0.3006 - dense_4_loss: 0.3103 - dense_5_loss: 0.2112 - dense_6_loss: 0.0798 - dense_7_loss: 0.0043 - val_loss: 0.8417 - val_dense_2_loss: 0.0851 - val_dense_3_loss: 0.2503 - val_dense_4_loss: 0.2562 - val_dense_5_loss: 0.1805 - val_dense_6_loss: 0.0675 - val_dense_7_loss: 0.0021\n",
      "Epoch 20/20\n",
      "135278/135278 [==============================] - 293s - loss: 0.9868 - dense_2_loss: 0.0901 - dense_3_loss: 0.2966 - dense_4_loss: 0.3094 - dense_5_loss: 0.2079 - dense_6_loss: 0.0785 - dense_7_loss: 0.0043 - val_loss: 0.8302 - val_dense_2_loss: 0.0892 - val_dense_3_loss: 0.2509 - val_dense_4_loss: 0.2544 - val_dense_5_loss: 0.1728 - val_dense_6_loss: 0.0607 - val_dense_7_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 20, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80288605472726182"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#activation function = tanh (instead of relu in initial model)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='tanh', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='tanh', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='tanh', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='tanh', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='tanh', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='tanh')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/20\n",
      "135278/135278 [==============================] - 286s - loss: 4.4195 - dense_9_loss: 0.4314 - dense_10_loss: 1.3758 - dense_11_loss: 1.6127 - dense_12_loss: 0.8230 - dense_13_loss: 0.1689 - dense_14_loss: 0.0077 - val_loss: 3.0475 - val_dense_9_loss: 0.2588 - val_dense_10_loss: 0.9018 - val_dense_11_loss: 1.0993 - val_dense_12_loss: 0.6564 - val_dense_13_loss: 0.1290 - val_dense_14_loss: 0.0022s: 0.4685 - dense_10_loss - ETA: 46s - loss: 4.6532 - dense_9_loss: 0.4636 - dense_10_loss: 1.4584 - dense_11_loss: 1.6964 - dense_12_loss: 0.85 - ETA: 43s - loss: 4.6347 - dense_9_loss: 0.4610 - dense_10_loss: 1.4519 - dense_11_loss: 1.6900 - dense_12_loss: 0.8510 - dense_13_loss:  - ETA: 41s - loss: 4.6243 - dense_9_loss: 0.4597 - dense_10_loss: 1.4478 - dense_11_loss: 1.6864 - dense_12_loss: 0.8495 - dense_13_loss: 0.1725 - dense_14 - ETA: 40s - loss: 4.6196 - dense_9_loss: 0.4591 - dense_10_loss: 1.4463 - dense_11_ - ETA: 35 - ETA: 6s - loss: 4.4494 - dense_9_loss: 0.4356 - den - ETA: 2s - loss: 4.4319 - dense_9_loss: 0.4332 - dense_10_loss: 1.3805 - dense\n",
      "Epoch 2/20\n",
      "135278/135278 [==============================] - 293s - loss: 2.7276 - dense_9_loss: 0.2273 - dense_10_loss: 0.8055 - dense_11_loss: 0.9740 - dense_12_loss: 0.5823 - dense_13_loss: 0.1352 - dense_14_loss: 0.0033 - val_loss: 2.1946 - val_dense_9_loss: 0.1933 - val_dense_10_loss: 0.6386 - val_dense_11_loss: 0.7682 - val_dense_12_loss: 0.4843 - val_dense_13_loss: 0.1088 - val_dense_14_loss: 0.0014 - dense_9_loss: 0.2342 - dense_10_loss: 0.8377 - dense_11_loss: 1.0181 - dense_12_loss: 0.6007 - dense_13_loss: 0.1355  - ETA: - ETA: 72s - loss: 2.8169 - dense_9_loss: 0.2333 - dense_10_loss: 0.8323 - dense_11_loss: 1.0118 - dense_12_loss: 0.6002 - dense_13_loss: 0.1358 - dense_14_ - ETA: 71s - loss: 2.8158 - dense_9_loss: 0.2332 - dense_10_loss: 0.8319 - dense_11_loss: 1.0114 - dense_12_loss: 0.6001 - dense_13_loss: 0.1357 - dense_14_loss: - ETA: 70s - loss: 2.8154 - dense_9_loss: 0.2333 - dense_10_loss: 0.8316 - dense_11_loss: 1.0110 - ETA: 65s - loss: 2.8091 - dense_9_loss: 0.2327 - dense_10_loss: 0.8305 - dense_11_ - ETA: 60s - loss: 2.8013 - dense_9_loss: 0.2318 - dense_10_loss: 0.8283 - dense_11_loss: 1.0059 - dense_12_loss: 0 - ETA: 56s - loss: 2.7975 - dense_9_loss: 0.2317 - dense_10_loss: 0.8266 - dense_11_loss: 1.0041 - dense_12_loss: 0.5960 - dense_13_loss: 0.1355 - dens - ETA: 55s - loss: 2.7950 - dense_9_loss: 0.2313 - dense_10_loss: 0.8259 - dense_11_loss: 1.0032 - dense_12_loss: 0.5956 - dense_13_loss: 0.1355 - dense_14_los - ETA: 55s - loss: 2.7942 - dense_9_loss: 0.2313 - dense_10_loss: 0.8258 - dense_11_loss: 1.0025 - dense_12_loss: 0.5956 - dens - ETA: 52s - loss: 2.7916 - dense_9_loss: 0.2308 - dense_10_loss: 0.8253 - dense_11_loss: 1.0012 - dense_12_loss:  - ETA: 48s - loss: 2.7875 - dense_9_loss: 0.2308 - dense_10_loss: 0.8245 - dense_11_loss: 0.9992 - dense_12_loss: 0.5939 - dense_13_loss: 0.1357 - dense_14_loss: 0.0 - ETA: 48s - loss: 2.7871 - dense_9_loss: 0.2308 - dense_10_loss: 0.8243 - dense_11_loss:  - ETA: 43s - loss: 2.7781 - dense_9_loss: 0.2298 - dense_10_loss: 0.822 - ETA - ETA: 26s - loss: 2.7539 - dense_9_loss: 0.2283 - dense_10_loss: 0.8136 - dense_11_loss: 0.9865 - dense_12_loss: 0.5872 - ETA: 23s - loss: 2.7513 - dense_9_loss: 0.2283 - dense_10_loss: 0.8130 - dense_11_loss: 0.9 - ETA: 18s - loss: 2.7468 - dense_9_loss: 0.2281 - dense_10_loss: 0.811 - ETA: 11s - loss: 2.7390 - dense_9_loss: 0.2280 - dense_10_loss: 0.8093 - dense_11_loss: 0.9794 - dense_12_loss: 0.5835 - dense_13_loss - ETA: 4s - loss: 2.7311 - dense_9_loss: 0.22\n",
      "Epoch 3/20\n",
      "135278/135278 [==============================] - 288s - loss: 2.1630 - dense_9_loss: 0.1823 - dense_10_loss: 0.6377 - dense_11_loss: 0.7508 - dense_12_loss: 0.4691 - dense_13_loss: 0.1203 - dense_14_loss: 0.0028 - val_loss: 1.7745 - val_dense_9_loss: 0.1492 - val_dense_10_loss: 0.5193 - val_dense_11_loss: 0.6057 - val_dense_12_loss: 0.3939 - val_dense_13_loss: 0.1049 - val_dense_14_loss: 0.0016.1793 - dense_9_loss: 0.1833 - dense_10_loss: 0.6416 - dense_11_loss: 0.7589 - dense_12_loss: 0 - ETA: 36s - loss: 2.1794 - dense_9_loss: 0.1834 - dense_10_loss: 0.6417 - dense_11_loss - ETA: 19s - loss: 2.1702 - d - ETA - ETA: 5s - l\n",
      "Epoch 4/20\n",
      "135278/135278 [==============================] - 287s - loss: 1.8304 - dense_9_loss: 0.1550 - dense_10_loss: 0.5427 - dense_11_loss: 0.6258 - dense_12_loss: 0.3955 - dense_13_loss: 0.1088 - dense_14_loss: 0.0026 - val_loss: 1.6945 - val_dense_9_loss: 0.1744 - val_dense_10_loss: 0.4646 - val_dense_11_loss: 0.5545 - val_dense_12_loss: 0.3997 - val_dense_13_loss: 0.1002 - val_dense_14_loss: 0.0011 ETA: 65s - loss: - ETA: 22s - loss: 1.8376 - den - ETA: 6s - loss: 1.8330 - dense_9_loss: 0.1554 - dense_10_loss: 0.5429 - dense_11_lo - ETA: 3s - loss: 1.8317 - dense_9_loss: 0.1552 - dense_10_\n",
      "Epoch 5/20\n",
      "135278/135278 [==============================] - 287s - loss: 1.6039 - dense_9_loss: 0.1341 - dense_10_loss: 0.4823 - dense_11_loss: 0.5399 - dense_12_loss: 0.3439 - dense_13_loss: 0.1017 - dense_14_loss: 0.0021 - val_loss: 1.4013 - val_dense_9_loss: 0.1229 - val_dense_10_loss: 0.4105 - val_dense_11_loss: 0.4668 - val_dense_12_loss: 0.3124 - val_dense_13_loss: 0.0876 - val_dense_14_loss: 0.0012\n",
      "Epoch 6/20\n",
      "135278/135278 [==============================] - 287s - loss: 1.4226 - dense_9_loss: 0.1177 - dense_10_loss: 0.4326 - dense_11_loss: 0.4756 - dense_12_loss: 0.3011 - dense_13_loss: 0.0937 - dense_14_loss: 0.0020 - val_loss: 1.3212 - val_dense_9_loss: 0.1181 - val_dense_10_loss: 0.4062 - val_dense_11_loss: 0.4300 - val_dense_12_loss: 0.2806 - val_dense_13_loss: 0.0852 - val_dense_14_loss: 0.0010dense_12_loss: 0.3010 - dense_13_loss: 0.0937 - dense\n",
      "Epoch 7/20\n",
      "135278/135278 [==============================] - 283s - loss: 1.2890 - dense_9_loss: 0.1061 - dense_10_loss: 0.3934 - dense_11_loss: 0.4272 - dense_12_loss: 0.2719 - dense_13_loss: 0.0885 - dense_14_loss: 0.0019 - val_loss: 1.2117 - val_dense_9_loss: 0.1056 - val_dense_10_loss: 0.3683 - val_dense_11_loss: 0.3952 - val_dense_12_loss: 0.2640 - val_dense_13_loss: 0.0778 - val_dense_14_loss: 7.3605e-04\n",
      "Epoch 8/20\n",
      "135278/135278 [==============================] - 287s - loss: 1.1734 - dense_9_loss: 0.0941 - dense_10_loss: 0.3593 - dense_11_loss: 0.3884 - dense_12_loss: 0.2463 - dense_13_loss: 0.0837 - dense_14_loss: 0.0016 - val_loss: 1.1455 - val_dense_9_loss: 0.0962 - val_dense_10_loss: 0.3444 - val_dense_11_loss: 0.3763 - val_dense_12_loss: 0.2511 - val_dense_13_loss: 0.0765 - val_dense_14_loss: 9.1672e-04\n",
      "Epoch 9/20\n",
      "135278/135278 [==============================] - 291s - loss: 1.0856 - dense_9_loss: 0.0852 - dense_10_loss: 0.3384 - dense_11_loss: 0.3561 - dense_12_loss: 0.2255 - dense_13_loss: 0.0788 - dense_14_loss: 0.0016 - val_loss: 1.1179 - val_dense_9_loss: 0.0982 - val_dense_10_loss: 0.3319 - val_dense_11_loss: 0.3640 - val_dense_12_loss: 0.2462 - val_dense_13_loss: 0.0766 - val_dense_14_loss: 0.00108 - dense_9_loss: 0.0851 - dense_10_loss: 0.3377 - dense_11_los - ETA: 43s - loss: 1.0804 - dense_9_loss: 0.0849 - dense_10_loss: 0.3378 - dense_11_loss: 0. - ETA: 38s - loss: 1.0810 - dense_9_loss: 0.0848 - dense_10_los - ETA: 31s - loss: 1.0819 - dense_9_loss: 0.0850 - dense_10_loss: 0.3386 - dense_11_loss: 0.3539 - dense_12_loss: 0.2240 - dense_13_loss - ETA: 29s - loss: 1.0821 - dense_9_loss: 0.0850 - dense_10_loss: 0.3386 - dense_11_loss: 0.3540 - dense_12_loss: 0.2240 - dense_13_loss: 0.0789 - ETA: 27s - loss: 1.0824 - dense_9_loss: 0.0849 - dense_10_loss: 0.3386 - dense_11_loss: 0.3544 - dense_12_loss: 0.2240 - dense_13 - ETA: 25s - loss: 1.0818 - dense_9_loss: 0.0847 - dense_10_loss: 0.3385 - dense_11_loss: 0.3543 - dense_12_l - ETA: 21s - loss: 1.0837 - dense_9_loss: 0.08 - ETA: 13s - loss: 1.0843 - dense_9_loss: 0.0850 - dense_10_loss: 0.3387 - dense_11_loss: 0.3554 - dense_12_loss: 0.2245 - dense_13_loss: 0.0792 - dense_14_loss - ETA: 13s - loss: 1.0842 - dense_9_loss: 0.0850 - dense_10_loss: 0.3386 - dense_11_loss: 0.3554 - dense_12_loss: 0.2244 - dense_13_loss: 0.0791 - dense_14\n",
      "Epoch 10/20\n",
      "135278/135278 [==============================] - 285s - loss: 1.0037 - dense_9_loss: 0.0781 - dense_10_loss: 0.3154 - dense_11_loss: 0.3278 - dense_12_loss: 0.2056 - dense_13_loss: 0.0752 - dense_14_loss: 0.0016 - val_loss: 1.0128 - val_dense_9_loss: 0.0944 - val_dense_10_loss: 0.3035 - val_dense_11_loss: 0.3283 - val_dense_12_loss: 0.2119 - val_dense_13_loss: 0.0737 - val_dense_14_loss: 9.4283e-04\n",
      "Epoch 11/20\n",
      "135278/135278 [==============================] - 276s - loss: 0.9376 - dense_9_loss: 0.0733 - dense_10_loss: 0.2943 - dense_11_loss: 0.3068 - dense_12_loss: 0.1901 - dense_13_loss: 0.0717 - dense_14_loss: 0.0014 - val_loss: 0.9943 - val_dense_9_loss: 0.1030 - val_dense_10_loss: 0.2948 - val_dense_11_loss: 0.3203 - val_dense_12_loss: 0.2043 - val_dense_13_loss: 0.0710 - val_dense_14_loss: 7.5399e-04\n",
      "Epoch 12/20\n",
      "135278/135278 [==============================] - 279s - loss: 0.8729 - dense_9_loss: 0.0666 - dense_10_loss: 0.2769 - dense_11_loss: 0.2837 - dense_12_loss: 0.1751 - dense_13_loss: 0.0690 - dense_14_loss: 0.0015 - val_loss: 0.9315 - val_dense_9_loss: 0.0811 - val_dense_10_loss: 0.2885 - val_dense_11_loss: 0.2968 - val_dense_12_loss: 0.1981 - val_dense_13_loss: 0.0665 - val_dense_14_loss: 6.8137e-04\n",
      "Epoch 13/20\n",
      "135278/135278 [==============================] - 271s - loss: 0.8260 - dense_9_loss: 0.0619 - dense_10_loss: 0.2620 - dense_11_loss: 0.2693 - dense_12_loss: 0.1650 - dense_13_loss: 0.0663 - dense_14_loss: 0.0015 - val_loss: 0.9093 - val_dense_9_loss: 0.0793 - val_dense_10_loss: 0.2755 - val_dense_11_loss: 0.2973 - val_dense_12_loss: 0.1940 - val_dense_13_loss: 0.0626 - val_dense_14_loss: 6.9203e-04\n",
      "Epoch 14/20\n",
      "135278/135278 [==============================] - 269s - loss: 0.7787 - dense_9_loss: 0.0583 - dense_10_loss: 0.2507 - dense_11_loss: 0.2514 - dense_12_loss: 0.1543 - dense_13_loss: 0.0627 - dense_14_loss: 0.0014 - val_loss: 0.8767 - val_dense_9_loss: 0.0772 - val_dense_10_loss: 0.2634 - val_dense_11_loss: 0.2814 - val_dense_12_loss: 0.1898 - val_dense_13_loss: 0.0643 - val_dense_14_loss: 5.4691e-04\n",
      "Epoch 15/20\n",
      "135278/135278 [==============================] - 268s - loss: 0.7361 - dense_9_loss: 0.0553 - dense_10_loss: 0.2362 - dense_11_loss: 0.2372 - dense_12_loss: 0.1452 - dense_13_loss: 0.0607 - dense_14_loss: 0.0014 - val_loss: 0.8448 - val_dense_9_loss: 0.0759 - val_dense_10_loss: 0.2612 - val_dense_11_loss: 0.2721 - val_dense_12_loss: 0.1740 - val_dense_13_loss: 0.0609 - val_dense_14_loss: 6.8041e-04\n",
      "Epoch 16/20\n",
      "135278/135278 [==============================] - 269s - loss: 0.7011 - dense_9_loss: 0.0530 - dense_10_loss: 0.2279 - dense_11_loss: 0.2250 - dense_12_loss: 0.1364 - dense_13_loss: 0.0576 - dense_14_loss: 0.0012 - val_loss: 0.8722 - val_dense_9_loss: 0.0801 - val_dense_10_loss: 0.2723 - val_dense_11_loss: 0.2732 - val_dense_12_loss: 0.1803 - val_dense_13_loss: 0.0657 - val_dense_14_loss: 6.9456e-04\n",
      "Epoch 17/20\n",
      "135278/135278 [==============================] - 268s - loss: 0.6747 - dense_9_loss: 0.0500 - dense_10_loss: 0.2197 - dense_11_loss: 0.2176 - dense_12_loss: 0.1303 - dense_13_loss: 0.0559 - dense_14_loss: 0.0012 - val_loss: 0.8047 - val_dense_9_loss: 0.0693 - val_dense_10_loss: 0.2461 - val_dense_11_loss: 0.2616 - val_dense_12_loss: 0.1683 - val_dense_13_loss: 0.0586 - val_dense_14_loss: 7.0868e-04\n",
      "Epoch 18/20\n",
      "135278/135278 [==============================] - 291s - loss: 0.6468 - dense_9_loss: 0.0478 - dense_10_loss: 0.2094 - dense_11_loss: 0.2082 - dense_12_loss: 0.1262 - dense_13_loss: 0.0542 - dense_14_loss: 0.0010 - val_loss: 0.8270 - val_dense_9_loss: 0.0751 - val_dense_10_loss: 0.2502 - val_dense_11_loss: 0.2717 - val_dense_12_loss: 0.1740 - val_dense_13_loss: 0.0555 - val_dense_14_loss: 5.3385e-04s - loss: 0.6362 - ETA: 97s - loss: 0.6365 - dense_9_loss: 0.0468 - dense_10_loss: 0.2070 - dense_11_loss: 0.2036 - dense_12_loss: 0.1244 - dens - ETA: 60s - loss: 0.6382 - dense_9_loss: 0.0464 - dense_10_loss: 0.2066 - dense_11_loss: 0.2052 - dense_12_loss:  - ETA: 45s - loss: 0.6406 - dense_9_loss: 0.0471 - dense_10_loss: 0.2067 - dense_11_loss: 0.2056 - dense_12_loss: 0.1264 - dense_13_loss: 0.0537 - dense_14_loss: 0 - ETA: 22s - loss: 0.6435 - dense_9_loss: 0.0472 - dense_10_loss: 0.2081 - dense_11_loss: 0.2068 - dense_12_loss: 0.1264 - dense_13_loss: 0.0539 - d - ETA: 21s - loss: 0.6434 - dense_9_loss: 0.0472 - dense_10_loss: 0.2082 - dense_11_loss: 0.2067 - dense_12_loss: 0.1264 - dense_13_loss: 0.053 - ETA: 19s - loss: 0.6439 - dense_9_loss: 0.0474 - dense_10_loss: 0.2083 - dense_11_loss: 0.2070 - dense_12_loss: 0.1264 - dense_13_loss: 0.0538 - dense_14_ - ETA: 19s - loss: 0.6442 - dense_9_loss: 0.0474  - ETA: - ETA: 5s - loss: 0.6464 - dense_9_loss: 0.0477 - dense_10_loss: 0.2093 - dense_11_loss: 0.2079 - dense_1 - ETA: 3s - loss: 0.6468 - dense_9_loss: 0.0478 - dense_10_loss: 0.2092\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 296s - loss: 0.6230 - dense_9_loss: 0.0461 - dense_10_loss: 0.2037 - dense_11_loss: 0.2002 - dense_12_loss: 0.1185 - dense_13_loss: 0.0533 - dense_14_loss: 0.0011 - val_loss: 0.7921 - val_dense_9_loss: 0.0682 - val_dense_10_loss: 0.2473 - val_dense_11_loss: 0.2543 - val_dense_12_loss: 0.1680 - val_dense_13_loss: 0.0536 - val_dense_14_loss: 8.0878e-04- dense - ETA: 124s - loss: 0.6090 - dense_9_loss: 0. - ETA: 108s - loss: 0.6106 - dense_9_loss: 0.0441 - dense_10_loss: 0.2004 - dense_11_loss: 0.1940 - dense_1 - ETA: 100s - loss: 0.6104 - dense_9_loss: 0.0441 - dense_10_loss: 0.2002 - dense_11_loss: 0.1949 - dense_12_loss: 0.1174 - dense_13_loss: 0.0529 - dense_14_loss: 8.7436e- - ETA: 100s - loss: 0.6104 - dense_9_loss: 0.0441 - dense_10_loss: 0.2002 - dense_11_loss: 0.1949 - dense_12_loss: 0.1174 - ETA: 97s - loss: 0.6114 - dense_9_loss: 0.0442 - dense_10_loss: 0.2008 - dense_11_loss: 0.1949 - dense_12_loss: 0.1176 - dense_13_loss: 0.0530 - dense_14_loss: 8.9660e - ETA: 97s - loss: 0.6113 - dense_9_loss: 0.0441 - dense_10_loss: 0.2008 - dense_11_loss: 0.1949 - dense_12_loss: 0.1176 - dense_13_loss: 0.0530 - den - ETA: 96s - loss: 0.6115 - dense_9_loss: 0.0442 - dense_10_loss: 0.2008 - dense_11_loss: 0.1951 - dense_12_loss: 0.1176 - dense_13_loss: 0.0530 - dense_14_loss:  - ETA: 95s - loss: 0.6115 - dense_9_loss: 0.0441 - dense_10_loss: 0.2008 - dense_11_loss: 0.1952 - dense_12_loss: 0.1175 - dense_ - ETA: 92s - loss: 0.6120 - dense_9_loss: 0.0442 - dense_10_loss: 0.2007 - dense_11_loss: 0.1954 - dense_12_loss: 0.1177 - dense_13_loss: 0.0531 - dense_1 - ETA: 91s - loss: 0 - ETA: 81 - ETA: 59s - loss: 0.6154 - dense_9_loss: 0.0448 - dense_10_loss: 0.2013 - dense_11 - ETA: 53s - loss: 0.6181 - dense_9_loss: 0.0452 - dense_10_loss: 0.2019 - dense_11_loss: 0.1980 - dense - ETA: 37s - loss: 0.6 - ETA: 16s - loss: 0.6212 - dense_9_loss: 0.0458 - dense_10_loss: 0.2026 - dense_11_loss: 0.1997 - dense_12_loss: 0.1186 - dense_13_loss: 0.0535 - dense_14_loss: 9.9628 - ETA: 15s - loss: 0.6214 - dense_9_loss: 0.0459 - dense_10_loss: 0.2026 - dense_11_loss: - ETA: 4s - loss: 0.6227 - dense_9_loss: 0.0460 - dense_10_loss: 0.2034 - dense_11_loss: 0.2003 - - ETA: 1s - loss: 0.6228 - dense_9_loss: 0.0459 - dense_10_loss: 0.2036 - dense_11_loss: 0.2002 - dense_12_loss: 0.1186 - dense_13_loss: 0. - ETA: 1s - loss: 0.6230 - dense_9_loss: 0.0460 - dense_10_loss: 0.2037 - dense_11_loss: 0.2003 - dense_12_loss: 0.1186 - dense_13_loss\n",
      "Epoch 20/20\n",
      "135278/135278 [==============================] - 294s - loss: 0.5950 - dense_9_loss: 0.0444 - dense_10_loss: 0.1943 - dense_11_loss: 0.1911 - dense_12_loss: 0.1139 - dense_13_loss: 0.0503 - dense_14_loss: 9.8822e-04 - val_loss: 0.8235 - val_dense_9_loss: 0.0729 - val_dense_10_loss: 0.2609 - val_dense_11_loss: 0.2636 - val_dense_12_loss: 0.1671 - val_dense_13_loss: 0.0581 - val_dense_14_loss: 8.2528e-04ss: 0.5816 - dense_9_loss: 0.0435 - dense_10_loss: 0.1905 - dense_11_loss: 0.1860 - - ETA: 148s - loss: 0.5827 - dense_9_loss: 0.0437 - dense_10_loss: 0.1904 - den - ETA: 145s - loss: 0.5834 - dense_9_loss: 0.0437 - dense_10_loss: 0.1909 - ETA: 141s - loss: 0.5844 - dense_9_loss: 0.0437 - dense_10_loss: 0.1914 - dense_11_loss: 0.1874 - dense_12_loss: 0.1113 - dense - ETA: 98s - loss: 0.5880 - dense_9_loss: 0.0436 - dense_10_loss: 0.1934 - dense_11_loss: 0.1885 - dense_12_loss: 0.1117 - dense_13_loss: 0.0497 - dense_14_l - ETA: 97s - loss: 0.5878 - dense_9_loss: 0.0437 - dense_10_loss: 0.1933 - dense_11_loss: 0.1885 - den - ETA: 81s - loss: 0.5876 - dense_9_loss: 0.0438 - dense_10_loss: 0.1932 - dense_11_loss: 0.1887 - de - ETA: 76s - loss: 0.5884 - dense_9_loss: 0.0438 - dense_10_loss: 0.1934 - dense_11_loss: 0.1888 - dense_12_l - ETA: 72s - loss: 0.5887 - dense_9_loss: 0.0438 - dense_10_loss: 0.1931 - dense_11_loss: 0.1888 - dense_12_loss: 0.1124 - dense_13_loss: 0.0497 - dense_14_lo - ETA: 71s - loss: 0.5896 - dense_9_loss: 0.0440 - dense_10_loss: 0.1932 - dense_11_loss: 0.1890 - dense_12_loss: 0.1127 - dense_13_loss: 0.0497 - dense - ETA: 70s - loss: 0.5897 - dense_9_loss: 0.0439 - dense_10_loss: 0.1934 - dense_11_loss: 0.1891 - dense_12_loss: 0.1126 - dense_13_loss:  - ETA: 68s - loss: 0.5894 - dense_9_loss: 0.0439 - dense_10_loss: 0.1933 - dense_11_loss: 0.1890 - dense_12_loss: 0.1125 - dense_13_loss: 0.0498 - dense_14_loss: 9.4756 - ETA: 67s - loss: 0.5894 - dense_9_loss: 0.0439 - dense_10_loss: 0.1933 - dense_11_l - ETA: 62s - loss: 0.5904 - dense_9_loss: 0.0439 - dense_10_loss: 0.1942 - dense_11_loss: 0.1890 - dense_12_loss: 0.1127 - dense_13_loss: 0.0497 - dense_14_loss: 9.3160e - ETA: 61s - loss: 0.5906 - dense_9_loss: 0.0438 - dense_10_loss: 0.1942 - dense_11_loss: 0.1891 - dense_12_loss: 0.1127 - ETA: 58s - loss: 0.5909 - dense_9_loss: 0.0440 - dense_10_loss: 0.1939 - dense_11_loss: 0.1890 - dense_12_loss: 0.1129 - dense_13_loss: 0.0500 - ETA: 56s - loss: 0.5909 - dense_9_loss: 0.0440 - dense_10_loss: 0.1937 - dense_11_loss: 0.1893 - dense_12_loss: 0.1129 - dense_13_loss: 0 - ETA: 54s - loss: 0.5909 - dense_9_loss: 0.0439 - dense_10_loss: 0.1937 - dense_11_loss: 0.1892 - dense_12_loss: 0.1129 - dense_13_los - ETA: 51s - loss: 0.5910 - dense_9_loss: 0.0439 - dense_10_loss: 0.1936 - dense_11_loss: 0.1894 - dense_12_loss: 0.1127 - dense_13_loss: 0.0503 - dense_14_loss: 0.001 - ETA: 51s - loss: 0.5910 - dense_9_loss: 0.0439 - dense_10_loss: 0.1936 - dense_11_loss: 0.1894 - dense_12_loss: 0.1127 - dense_13_loss: 0.0504  - ETA: 50s - loss: 0.5907 - dense_9_loss: 0.0439 - dense_10_loss: 0.1936 - dense_11_loss: 0.1893 - dense_12_loss: 0.1125 - dense - ETA: 47s - loss: 0.5923 - dense_9_loss: 0.0442 - dense_10_loss: 0.1940 - dense_11_loss: 0.1898 - dense_12_loss: 0.1128 - dense_13_loss: 0.0504 - dense_14_loss: 0 - ETA: 47s - loss: 0.5925 - dense_9_loss: 0.0443 - dense_10_loss: 0.1940 - dense_11_loss: 0.1899 - dense - ETA: 42s - loss: 0.5925 - dense_9_loss: 0.0445 - dense_10_loss: 0.1938 - dense_11_loss: 0.1899 - dense_12_loss: 0.1129 - dense_13_loss - ETA: 40s - loss: 0.5922 - dense_9_loss: 0.0444 - dense_10_los - ETA: 33s - loss: 0.5924 - dense_9_loss: 0.0445 - dense_10_loss: 0.1933 - dense_11_loss: 0.1902 - dense_12_loss: 0.1131 - dense_ - ETA: 31s - loss: 0.5921 - dense_9_loss: 0.0445 - dense_10_loss: 0.1929 - dense_11_loss: 0.1902 - dense_12_loss: 0.1132 - dense_13_loss: 0.0504 - dens - ETA: 29s - loss: 0.5922 - dense_9_loss: 0.0444 - dense_10_loss: 0.1930 - dense_11_loss: 0.1902 - dense_12_loss: 0.1131 - dense_13_loss: 0.05 - ETA: 28s - loss: 0.5920 - dense_9_loss: 0.0444 - dense_10_loss: 0.1931 - dense_11_loss: 0.190 - ETA: 11s - loss: 0.5936 - dense_9_loss: 0.0444 - dense_10_loss: 0.1937 - dense_11_loss: 0.190 - ETA: 8s - loss: 0.5942 - dense_9_loss: 0.0444 - dense_10_loss: 0.1940 - dense_11_loss: 0.1907 - dense_12_loss: 0.1136 - dense_13_loss: 0.0505 - - ETA: 7s - loss: 0.5942 - dense_9_loss: 0.0444 - dense_10_loss: 0.1941 - dense_11_loss - ETA: 4s - loss: 0.5939 - \n"
     ]
    }
   ],
   "source": [
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 20, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78234836237351058"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#activation function = sigmoid (instead of relu in initial model)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='sigmoid', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='sigmoid', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='sigmoid', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='sigmoid', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='sigmoid', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='sigmoid')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/20\n",
      "135278/135278 [==============================] - 296s - loss: 6.5545 - dense_16_loss: 0.9654 - dense_17_loss: 2.0336 - dense_18_loss: 2.1914 - dense_19_loss: 1.1200 - dense_20_loss: 0.2164 - dense_21_loss: 0.0278 - val_loss: 6.0743 - val_dense_16_loss: 0.7854 - val_dense_17_loss: 1.9864 - val_dense_18_loss: 2.1201 - val_dense_19_loss: 1.0109 - val_dense_20_loss: 0.1695 - val_dense_21_loss: 0.0021oss: 9.9230 - dense_16_loss: 1.3482 - dense_17_loss: 2.3479 - dense_18_loss: 2.4523 - dense_19_loss: 2.1029 - dense_20_loss: 0.8333 - dense_21_loss: 0.838 - ETA: 349s - loss: 9.9070 - dense_16_loss: 1.3468 - dense_17_loss: 2.3470 - dense_18_loss: 2.4525 - dense_1 - ETA: 314s - loss: 8.9843 - dense_16_loss: 1.2939 - dense_17_loss: 2.2670 - dense_18_loss: 2.4135 - dense_19_loss: 1.772 - ETA: 300s - loss: 8.5572 - dense_16_loss: 1.2697 - dense_17_loss: 2.2285 - dense_18_loss: 2.3867 - dense_19_loss: 1.6352 - dense_20_loss: 0.5587 - dense - ETA: 296s - loss: 8.4513 - dense_16_loss: 1.2661 - dense_17_loss: 2.2162 - dense_18_loss: 2.3783 - dense_19_loss: 1.6047 - dense_20_loss: 0.5375 - dense_21_loss: 0.44 - ETA: 296s - loss: 8.4338 - dense_16_loss: 1.2642 - dense_17_loss: 2.2148 - dense_18_loss: 2.3767 - dense_19_loss: 1.59 - ETA: 287s - loss: 8.1721 - dense_16_loss: 1.2434 - dense_17_loss: 2.1818 - dense_18_loss: 2.3621 - dense_19_loss: 1.5334 - dense_20_lo - ETA: 282s - loss: 8.0148 - dense_16_loss: 1.2296 - dense_17_loss: 2.1665 - dense_18_loss: 2.3500 - dense_19_loss: 1.4896 - dense_20_loss: 0.446 - ETA: 278s - loss: 7.9260 - dense_16_loss: 1.2253 - dense_17_loss: 2.1561 - dense_18_loss: 2.3405 - dense_19_loss: 1.4661 - dense_20_loss: 0.4289 - dense_21_loss: - ETA: 278s - loss: 7.9046 - dense_16_loss: 1.2240 - dense_17_loss: 2.1536 - dense_18_loss: 2.3391 - dense_19_loss: 1.4608 - dense_20_loss: 0.4241 - dense_21_loss:  - ETA: 277s - loss: 7.8906 - dense_16_loss: 1.2234 - dense_17_loss: 2.1520 - dense_18_loss: 2.3371 - dense_19_loss: 1.4582 - dense_20_loss: 0.4220 - den - ETA: 275s - loss: 7.8390 - dense_16_loss: 1.2194 - dense_17_loss: 2.1457 - dense_18_loss: 2.3315 - dense_19_loss: 1.4457 - dense_20_loss: 0.4131 - d - ETA: 272s - loss: 7.7858 - dense_16_loss: 1.2152 - dense_17_loss: 2.1411 - dense_18_loss: 2.3261 - dense_19_loss: 1.4323 - dense_20_loss: 0.4018 - dense_21_ - ETA: 271s - loss: 7.7650 - dense_16_loss: 1.2145 - dense_17_loss: 2.1393 - dense_18_loss: 2.3243 - dense_19_loss: 1.4293 - de - ETA: 266s - los - ETA: 252s - loss: 7.4837 - dense_16_loss: 1.1909 - dense_17_loss: 2.1121 - dense_18_loss: 2.2965 - dense_19_loss: 1.3630 - dense_20_loss: 0.3454 - d - ETA: 250s - loss: 7.4651 - dense_16_loss: 1.1895 - dense_17_loss: 2.1113 - dense_18_loss: 2.2936 - dense_19_loss: 1.3582 - dense_20_loss: 0.3424 - dense_21_loss: 0. - ETA: 250s - loss: 7.4595 - dense_16_loss: 1.1890 - dense_17_loss: 2.1112 - dense_18_loss: 2.2930 - dense_19_loss: 1.3562 - dense_20_loss: 0.3413 - dense_21_l - ETA: 249s - loss: 7.4477 - dense_16_loss: 1.1874 - dense_17_loss: 2.1090 - dense_18_loss: 2.2933 - dense_19_loss: 1.3534 - dense_20_loss: 0.3387 - dense_21_los - ETA: 248s - loss: 7.4367 - dense_16_loss: 1.1859 - dense_17_loss: 2.1086 - dense_18_loss: 2.2923 - dense_19_loss: 1.3499 - dense_20_loss: 0.3364 - dens - ETA: 247s - loss: 7.4213 - dense_16_loss: 1.1850 - dense_17_loss: 2.1067 - dense_18_loss: 2.2918 - dense_19_loss: 1.3452 - dense_20_loss: 0.3333 - ETA: 245s - loss: 7.3984 - dense_16_loss: 1.1817 - dense_17_loss: 2.1052 - dense_18_loss: 2.2910 - dense_19_loss: 1.3396 - dense_20_loss: 0.3272 - dense_21_loss: 0.15 - ETA: 245s - loss: 7.3966 - dense_16_loss: 1.1817 - dense_17_loss: 2.1050 - dense_18_loss: 2.2908 - dense_19_loss: 1.3393 - dense_20_l - ETA: 242s - loss: 7.3704 - dense_16_loss: 1.1797 - dense_17_loss: 2.1021 - dense_18_loss: - ETA: 236s - loss: 7.3203 - dense_16_loss: 1.1773 - dense_17_loss: 2.0972 - dense_18_loss: 2.2816 - dense_19_loss: 1.3164 - dense_20_loss: 0.3155 - dense_21_loss: 0.1 - ETA: 236s - loss: 7.3187 - dense_16_loss: 1.1771 - dense_17_loss: 2.0967 - dense_18_loss: 2.2814 - dense_ - ETA: 231s - loss: 7.2883 - dense_16_loss: 1.1744 - dense_17_loss: 2.0917 - dense_18_loss: 2.2776 - dense_19_loss: 1.3110 - dense_20_loss: 0. - ETA: 229s - loss: 7.2733 - dense_16_loss: 1.1730 - dense_17_loss: 2.0898 - dense_18_loss: 2.2757 - dense_19_loss: 1.3061 - dense_20_loss: 0.3105 -  - ETA: 214s - loss: 7.1707 - dense_16_loss: 1.1567 - dense_17_loss: 2.0820 - dense_18_loss: 2.2647 - dense_19_loss: 1.2756 - dense_20_loss: 0.2933 - dense_21_loss: 0.09 - ETA: 214s - loss: 7.1693 - dense_16_loss: 1.1564 - dense_17_loss: 2.0821  - ETA: 207s - loss: 7.1278 - dense_16_loss: 1.1475 - dense_17_loss: 2.0772 - dense_18_loss: 2.2603 - dense_19_loss: 1.2644 -  - ETA: 204s - loss: 7.1072 - dense_16_loss: 1.1430 - dense_17_loss: 2.0745 - dense_18_loss: 2.2590 - dense_19_loss: 1.2583 - dense_20_loss: 0.2852 - - ETA: 203s - loss: 7.0990 - dense_16_loss: 1.1412 - dense_17_loss: 2.0745 - dense_18_loss: 2.2 - ETA: 197s - loss: 7.0688 - dense_16_loss: 1.1334 - dense_17_loss: 2.0723 - dense_18_loss: 2.2546 - dense_19_loss: 1.2477 - dense_20_loss: 0. - ETA: 195s - loss: 7.0585 - dense_16_loss: 1.1311 - dense_17_loss: 2.07 - ETA: 40s - loss: 6.6127 - dense_16_loss: 0.9866 - dense_17_lo - ETA: 13s - loss: 6.5723 - dense_16_loss: 0.9723 - dense_17_loss: 2.0348 - dense_18_loss: 2.1942 - dense_19_loss: 1.1241 - dense_20_loss: 0.2179 - - ETA: 12s - loss: 6.5716 - dense_16_loss: 0.9720 - dense_17_loss: 2.0347 - dense_18_loss: 2.1942 - dense_19_loss - ETA: 10s - loss: 6.5688 - dense_16_loss: 0.9709 - dense_17_loss: 2.0347 - dense_18_loss: 2.1938 - dense_19_loss: 1.1232 - dense_20_loss:  - ETA: 9s - loss: 6.5674 - dense_16_loss: 0.9703 - dense_17_loss: 2.0345 - dense_18_loss: 2 - ETA: 4s - loss: 6.5610 - dense_16_loss: 0.9676 - dense_17_loss: 2.0341 - dense_18_loss: 2.1923 - \n",
      "Epoch 2/20\n",
      "135278/135278 [==============================] - 294s - loss: 6.0357 - dense_16_loss: 0.7522 - dense_17_loss: 1.9880 - dense_18_loss: 2.1107 - dense_19_loss: 1.0074 - dense_20_loss: 0.1732 - dense_21_loss: 0.0043 - val_loss: 6.1421 - val_dense_16_loss: 0.8519 - val_dense_17_loss: 1.9822 - val_dense_18_loss: 2.1453 - val_dense_19_loss: 0.9895 - val_dense_20_loss: 0.1710 - val_dense_21_loss: 0.0021nse_17_loss: 1.9977 - dense_18_loss: 2.1462 - dense_19_loss:  - ETA: 242s - loss: 6.1813 - dense_16_loss: 0.8145 - dense_17_loss: 1.9981 - dense_18_loss: 2.1439 - dense_19_loss: 1.0463 - dense_20_loss: 0.1743 - d - ETA: 240s - loss: 6.1758 - dense_16_loss: 0.8131 - dense_17_loss: 1.9981 - dense_18_loss: 2.1426 - dense_19_loss: 1.0437 - dense_20_loss: 0.1741 - dense_21 - ETA: 239s - loss: 6.1774 - dense_16_loss: 0.8136 - dense_17_loss: 1.9961 - dense_18_loss: 2.1429 - dense_19_los - ETA: 236s - loss: 6.1728 - dense_16_loss: 0.8123 - dense_17_loss: 1.9973 - dense_18_loss: 2.1402 - dense_19 - ETA: 209s - loss: 6.1511 - dense_16_loss: 0.8051 - dense_17_loss: 1.9973 - dense_18_loss: 2.1352 - - ETA: 204s - loss: 6.1453 - dense_16_loss: 0.8031 - dense_17_loss: 1.9961 - dense_18_loss: - ETA: 199s - loss: 6.1474 - dense_16_loss: 0.8023 - dense_17_loss: 1.9958 - dense_18_loss: 2.1340 - dense_19_loss: 1.0351 - dense_20_loss: 0.1774 - dense_21_loss: 0. - ETA: 199s - loss: 6.1481 - dense_16_loss: 0.8024 - dense_17_loss: 1.9960 - dense_18_loss: 2.1337 - dense_19_loss: 1.0357 - dense_20_l - ETA: 196s - loss: 6.1486 - dense_16_loss: 0.8017 - dense_17_loss: 1.9954 - dense_18_l - ETA: 179s - loss: 6.1319 - dense_16_loss: 0.7957 - dense_17_loss: 1.9939 - dense_18_loss: 2.1305 - dense_19_loss: 1.0333 - dense_20_loss: 0.1759 - dens - ETA: 178s - loss: 6.1314 - dense_16_loss: 0.7953 - dense_17_loss: 1.9939 - dense_18_loss: 2.1307 - dense_19_loss: 1.0332 - dense_20_loss: 0.1757 - dense_21_loss: 0.002 - ETA: 178s - loss: 6.1314 - dense_16_loss: 0.7952 - dense_17_loss: 1.9939 - dense_18_loss - ETA: 151s - loss: 6.1162 - dense_16_loss: 0.7889 - dense_17_loss: 1.9927 - dense_18_loss: 2.1283 - de - ETA: 146s - loss: 6.1163 - dense_16_loss: 0.7884 - dense_17_loss: 1.9930 - dense_18_loss: 2.1280 - dense_19_loss: 1.0292 - dense_20_loss: 0.1741 - d - ETA: 145s - loss: 6.1159 - dense_16_loss: 0.7882 - dense_17_loss: 1.9934 - den - ETA: 139s - loss: 6.1098 - dense_16_loss: 0.7854 - dense_17_loss: 1.9930 - dense_18_loss: 2.1270 - dense_19_loss: 1.0270 - dense_20_loss: 0.1737 - dense_21_lo - ETA: 138s - loss: 6.1096 - dense_16_loss: 0.7852 - - ETA: 130s - loss: 6.1034 - dense_16_loss: 0.7824  - ETA: 122s - loss: 6.1036 - dense_16_loss: 0.7823 - dense_17_loss: 1.9925 - dense_18_lo - ETA: 117s - loss: 6.1015 - dense_16_loss: 0.7811 - dense_17_loss: 1 - ETA: 65s - loss: 6.0749 - dense_16_loss: 0.7689 - dense_17_loss: 1.9917 - dense_18_loss: 2.1187 - dense_19_loss: 1.0178 - dense_20_loss: 0. - ETA: 64s - loss: 6.0737 - dense_16_loss: 0.7684 - dense_17_loss - ETA: 55s - loss: 6.0706 - - ETA: 50s - loss: 6.0657 - dense_16_loss: 0.7653 - dense_1 - ETA: 41s - loss: 6.0591 - dense_16_loss: 0.7621 - dense_17_loss: 1.9906 - dense_18_loss - ETA: 32s - loss: 6.0546 - dense_16_loss: 0.7604 - dense_17_loss: 1.9900 - dense_18_loss: 2.1142 - dense_19_loss: 1.0115 - dense - ETA: 31s - loss: 6.0531 - dense_16_loss: 0.7598 - dense_17_loss: 1.9900 - dense_18_loss: 2.1137 - den - ETA: 29s - loss: 6.0517 - dense_16_loss: 0.7591 - dense_17_loss: 1.9896 - dense_18_loss: 2.1134 - dense_19_ - ETA: 27s - los\n",
      "Epoch 3/20\n",
      "135278/135278 [==============================] - 290s - loss: 5.7877 - dense_16_loss: 0.6477 - dense_17_loss: 1.9510 - dense_18_loss: 2.0539 - dense_19_loss: 0.9606 - dense_20_loss: 0.1702 - dense_21_loss: 0.0043 - val_loss: 5.6744 - val_dense_16_loss: 0.6297 - val_dense_17_loss: 1.9214 - val_dense_18_loss: 2.0278 - val_dense_19_loss: 0.9312 - val_dense_20_loss: 0.1622 - val_dense_21_loss: 0.0021\n",
      "Epoch 4/20\n",
      "135278/135278 [==============================] - 284s - loss: 5.5719 - dense_16_loss: 0.5845 - dense_17_loss: 1.8885 - dense_18_loss: 1.9929 - dense_19_loss: 0.9336 - dense_20_loss: 0.1681 - dense_21_loss: 0.0043 - val_loss: 5.3438 - val_dense_16_loss: 0.5289 - val_dense_17_loss: 1.8220 - val_dense_18_loss: 1.9439 - val_dense_19_loss: 0.8870 - val_dense_20_loss: 0.1598 - val_dense_21_loss: 0.0021\n",
      "Epoch 5/20\n",
      "135278/135278 [==============================] - 283s - loss: 5.2024 - dense_16_loss: 0.5071 - dense_17_loss: 1.7292 - dense_18_loss: 1.9013 - dense_19_loss: 0.8946 - dense_20_loss: 0.1660 - dense_21_loss: 0.0043 - val_loss: 4.8730 - val_dense_16_loss: 0.4413 - val_dense_17_loss: 1.6144 - val_dense_18_loss: 1.8273 - val_dense_19_loss: 0.8344 - val_dense_20_loss: 0.1534 - val_dense_21_loss: 0.0021\n",
      "Epoch 6/20\n",
      "135278/135278 [==============================] - 322s - loss: 4.7365 - dense_16_loss: 0.4150 - dense_17_loss: 1.5453 - dense_18_loss: 1.7724 - dense_19_loss: 0.8371 - dense_20_loss: 0.1624 - dense_21_loss: 0.0043 - val_loss: 4.3977 - val_dense_16_loss: 0.3687 - val_dense_17_loss: 1.4201 - val_dense_18_loss: 1.6581 - val_dense_19_loss: 0.7970 - val_dense_20_loss: 0.1517 - val_dense_21_loss: 0.0021\n",
      "Epoch 7/20\n",
      "135278/135278 [==============================] - 329s - loss: 4.3075 - dense_16_loss: 0.3515 - dense_17_loss: 1.3827 - dense_18_loss: 1.6205 - dense_19_loss: 0.7903 - dense_20_loss: 0.1582 - dense_21_loss: 0.0043 - val_loss: 4.0747 - val_dense_16_loss: 0.3589 - val_dense_17_loss: 1.2729 - val_dense_18_loss: 1.5066 - val_dense_19_loss: 0.7873 - val_dense_20_loss: 0.1469 - val_dense_21_loss: 0.0021\n",
      "Epoch 8/20\n",
      "135278/135278 [==============================] - 280s - loss: 3.9356 - dense_16_loss: 0.3142 - dense_17_loss: 1.2406 - dense_18_loss: 1.4706 - dense_19_loss: 0.7535 - dense_20_loss: 0.1524 - dense_21_loss: 0.0043 - val_loss: 3.5880 - val_dense_16_loss: 0.2742 - val_dense_17_loss: 1.1156 - val_dense_18_loss: 1.3447 - val_dense_19_loss: 0.7083 - val_dense_20_loss: 0.1431 - val_dense_21_loss: 0.0021\n",
      "Epoch 9/20\n",
      "135278/135278 [==============================] - 275s - loss: 3.6288 - dense_16_loss: 0.2862 - dense_17_loss: 1.1214 - dense_18_loss: 1.3498 - dense_19_loss: 0.7213 - dense_20_loss: 0.1458 - dense_21_loss: 0.0043 - val_loss: 3.3074 - val_dense_16_loss: 0.2518 - val_dense_17_loss: 1.0028 - val_dense_18_loss: 1.2387 - val_dense_19_loss: 0.6777 - val_dense_20_loss: 0.1342 - val_dense_21_loss: 0.0021\n",
      "Epoch 10/20\n",
      "135278/135278 [==============================] - 275s - loss: 3.3650 - dense_16_loss: 0.2611 - dense_17_loss: 1.0225 - dense_18_loss: 1.2448 - dense_19_loss: 0.6922 - dense_20_loss: 0.1401 - dense_21_loss: 0.0043 - val_loss: 3.1197 - val_dense_16_loss: 0.2524 - val_dense_17_loss: 0.9257 - val_dense_18_loss: 1.1413 - val_dense_19_loss: 0.6683 - val_dense_20_loss: 0.1299 - val_dense_21_loss: 0.0021\n",
      "Epoch 11/20\n",
      "135278/135278 [==============================] - 275s - loss: 3.1422 - dense_16_loss: 0.2403 - dense_17_loss: 0.9444 - dense_18_loss: 1.1535 - dense_19_loss: 0.6647 - dense_20_loss: 0.1350 - dense_21_loss: 0.0043 - val_loss: 2.8863 - val_dense_16_loss: 0.2256 - val_dense_17_loss: 0.8437 - val_dense_18_loss: 1.0513 - val_dense_19_loss: 0.6413 - val_dense_20_loss: 0.1223 - val_dense_21_loss: 0.0021\n",
      "Epoch 12/20\n",
      "135278/135278 [==============================] - 276s - loss: 2.9477 - dense_16_loss: 0.2237 - dense_17_loss: 0.8785 - dense_18_loss: 1.0723 - dense_19_loss: 0.6377 - dense_20_loss: 0.1312 - dense_21_loss: 0.0043 - val_loss: 2.6438 - val_dense_16_loss: 0.1946 - val_dense_17_loss: 0.7771 - val_dense_18_loss: 0.9570 - val_dense_19_loss: 0.5929 - val_dense_20_loss: 0.1201 - val_dense_21_loss: 0.0021\n",
      "Epoch 13/20\n",
      "135278/135278 [==============================] - 276s - loss: 2.7721 - dense_16_loss: 0.2088 - dense_17_loss: 0.8196 - dense_18_loss: 1.0001 - dense_19_loss: 0.6115 - dense_20_loss: 0.1278 - dense_21_loss: 0.0043 - val_loss: 2.4852 - val_dense_16_loss: 0.1890 - val_dense_17_loss: 0.7144 - val_dense_18_loss: 0.8851 - val_dense_19_loss: 0.5709 - val_dense_20_loss: 0.1237 - val_dense_21_loss: 0.0021\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 269s - loss: 2.6136 - dense_16_loss: 0.1970 - dense_17_loss: 0.7687 - dense_18_loss: 0.9349 - dense_19_loss: 0.5831 - dense_20_loss: 0.1256 - dense_21_loss: 0.0043 - val_loss: 2.3102 - val_dense_16_loss: 0.1689 - val_dense_17_loss: 0.6654 - val_dense_18_loss: 0.8238 - val_dense_19_loss: 0.5382 - val_dense_20_loss: 0.1118 - val_dense_21_loss: 0.0021\n",
      "Epoch 15/20\n",
      "135278/135278 [==============================] - 268s - loss: 2.4788 - dense_16_loss: 0.1870 - dense_17_loss: 0.7274 - dense_18_loss: 0.8785 - dense_19_loss: 0.5597 - dense_20_loss: 0.1220 - dense_21_loss: 0.0043 - val_loss: 2.2034 - val_dense_16_loss: 0.1698 - val_dense_17_loss: 0.6276 - val_dense_18_loss: 0.7766 - val_dense_19_loss: 0.5170 - val_dense_20_loss: 0.1102 - val_dense_21_loss: 0.0021\n",
      "Epoch 16/20\n",
      "135278/135278 [==============================] - 268s - loss: 2.3541 - dense_16_loss: 0.1799 - dense_17_loss: 0.6859 - dense_18_loss: 0.8282 - dense_19_loss: 0.5359 - dense_20_loss: 0.1199 - dense_21_loss: 0.0043 - val_loss: 2.0924 - val_dense_16_loss: 0.1559 - val_dense_17_loss: 0.6049 - val_dense_18_loss: 0.7288 - val_dense_19_loss: 0.4923 - val_dense_20_loss: 0.1083 - val_dense_21_loss: 0.0021\n",
      "Epoch 17/20\n",
      "135278/135278 [==============================] - 268s - loss: 2.2404 - dense_16_loss: 0.1698 - dense_17_loss: 0.6511 - dense_18_loss: 0.7832 - dense_19_loss: 0.5144 - dense_20_loss: 0.1177 - dense_21_loss: 0.0043 - val_loss: 2.0094 - val_dense_16_loss: 0.1646 - val_dense_17_loss: 0.5625 - val_dense_18_loss: 0.6956 - val_dense_19_loss: 0.4777 - val_dense_20_loss: 0.1070 - val_dense_21_loss: 0.0021\n",
      "Epoch 18/20\n",
      "135278/135278 [==============================] - 268s - loss: 2.1409 - dense_16_loss: 0.1635 - dense_17_loss: 0.6203 - dense_18_loss: 0.7416 - dense_19_loss: 0.4956 - dense_20_loss: 0.1158 - dense_21_loss: 0.0043 - val_loss: 1.9469 - val_dense_16_loss: 0.1529 - val_dense_17_loss: 0.5332 - val_dense_18_loss: 0.6758 - val_dense_19_loss: 0.4777 - val_dense_20_loss: 0.1051 - val_dense_21_loss: 0.0021\n",
      "Epoch 19/20\n",
      "135278/135278 [==============================] - 268s - loss: 2.0499 - dense_16_loss: 0.1556 - dense_17_loss: 0.5946 - dense_18_loss: 0.7072 - dense_19_loss: 0.4738 - dense_20_loss: 0.1143 - dense_21_loss: 0.0043 - val_loss: 1.8170 - val_dense_16_loss: 0.1460 - val_dense_17_loss: 0.5059 - val_dense_18_loss: 0.6177 - val_dense_19_loss: 0.4426 - val_dense_20_loss: 0.1027 - val_dense_21_loss: 0.0021\n",
      "Epoch 20/20\n",
      "135278/135278 [==============================] - 268s - loss: 1.9630 - dense_16_loss: 0.1498 - dense_17_loss: 0.5665 - dense_18_loss: 0.6739 - dense_19_loss: 0.4568 - dense_20_loss: 0.1117 - dense_21_loss: 0.0043 - val_loss: 1.7236 - val_dense_16_loss: 0.1331 - val_dense_17_loss: 0.4875 - val_dense_18_loss: 0.5823 - val_dense_19_loss: 0.4170 - val_dense_20_loss: 0.1016 - val_dense_21_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 20, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53068678522244173"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

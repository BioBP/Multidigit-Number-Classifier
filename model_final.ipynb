{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33402, 62)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training label\n",
    "labels = np.load('labels.npy')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 54, 54, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img as train data\n",
    "size = labels.shape[0]\n",
    "numsample = 5\n",
    "folder = 'train/croppedsampled/'\n",
    "images = []\n",
    "\n",
    "for k in range(numsample):\n",
    "    for i in range(size):\n",
    "        im = Image.open(folder+str(i+1)+'_'+str(k)+'.png')\n",
    "        images.append(np.asarray(im))\n",
    "        \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replicate labels to cover all sample\n",
    "labels = np.tile(labels,(5,1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split training set and validation set\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.1, random_state=0)\n",
    "train_index, test_index = next(rs.split(images)) #just 1\n",
    "test_images = images[test_index]\n",
    "test_labels = labels[test_index]\n",
    "images = images[train_index]\n",
    "labels = labels[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial model (same as initial model in other program)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 54, 54, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 54, 54, 64)    1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 27, 27, 64)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 27, 27, 64)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 27, 27, 128)   73856       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 13, 13, 128)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 13, 13, 128)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 13, 13, 192)   221376      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 6, 6, 192)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 6, 6, 192)     0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 6, 6, 256)     442624      dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 3, 3, 256)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 3, 3, 256)     0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 3, 3, 256)     590080      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 1, 1, 256)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1, 1, 256)     0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 256)           0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           32896       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 7)             903         dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,370,622\n",
      "Trainable params: 1,370,622\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/50\n",
      "135278/135278 [==============================] - 284s - loss: 0.9680 - dense_54_loss: 0.0882 - dense_55_loss: 0.2929 - dense_56_loss: 0.3092 - dense_57_loss: 0.1996 - dense_58_loss: 0.0738 - dense_59_loss: 0.0043 - val_loss: 0.8112 - val_dense_54_loss: 0.0865 - val_dense_55_loss: 0.2524 - val_dense_56_loss: 0.2417 - val_dense_57_loss: 0.1719 - val_dense_58_loss: 0.0566 - val_dense_59_loss: 0.0021\n",
      "Epoch 2/50\n",
      "135278/135278 [==============================] - 282s - loss: 0.9740 - dense_54_loss: 0.0886 - dense_55_loss: 0.2983 - dense_56_loss: 0.3065 - dense_57_loss: 0.2028 - dense_58_loss: 0.0736 - dense_59_loss: 0.0043 - val_loss: 0.8762 - val_dense_54_loss: 0.0970 - val_dense_55_loss: 0.2596 - val_dense_56_loss: 0.2658 - val_dense_57_loss: 0.1802 - val_dense_58_loss: 0.0714 - val_dense_59_loss: 0.0021\n",
      "Epoch 3/50\n",
      "135278/135278 [==============================] - 281s - loss: 0.9450 - dense_54_loss: 0.0866 - dense_55_loss: 0.2871 - dense_56_loss: 0.2976 - dense_57_loss: 0.1979 - dense_58_loss: 0.0714 - dense_59_loss: 0.0043 - val_loss: 0.7518 - val_dense_54_loss: 0.0716 - val_dense_55_loss: 0.2302 - val_dense_56_loss: 0.2335 - val_dense_57_loss: 0.1603 - val_dense_58_loss: 0.0541 - val_dense_59_loss: 0.0021\n",
      "Epoch 4/50\n",
      "135278/135278 [==============================] - 280s - loss: 0.9475 - dense_54_loss: 0.0863 - dense_55_loss: 0.2885 - dense_56_loss: 0.2992 - dense_57_loss: 0.1963 - dense_58_loss: 0.0728 - dense_59_loss: 0.0043 - val_loss: 0.7773 - val_dense_54_loss: 0.0773 - val_dense_55_loss: 0.2423 - val_dense_56_loss: 0.2336 - val_dense_57_loss: 0.1670 - val_dense_58_loss: 0.0551 - val_dense_59_loss: 0.0021\n",
      "Epoch 5/50\n",
      "135278/135278 [==============================] - 289s - loss: 0.9396 - dense_54_loss: 0.0844 - dense_55_loss: 0.2864 - dense_56_loss: 0.2978 - dense_57_loss: 0.1933 - dense_58_loss: 0.0734 - dense_59_loss: 0.0043 - val_loss: 1.0700 - val_dense_54_loss: 0.1555 - val_dense_55_loss: 0.3082 - val_dense_56_loss: 0.3153 - val_dense_57_loss: 0.2245 - val_dense_58_loss: 0.0644 - val_dense_59_loss: 0.0021\n",
      "Epoch 6/50\n",
      "135278/135278 [==============================] - 281s - loss: 0.9461 - dense_54_loss: 0.0851 - dense_55_loss: 0.2920 - dense_56_loss: 0.2975 - dense_57_loss: 0.1963 - dense_58_loss: 0.0709 - dense_59_loss: 0.0043 - val_loss: 1.1486 - val_dense_54_loss: 0.1299 - val_dense_55_loss: 0.3711 - val_dense_56_loss: 0.3740 - val_dense_57_loss: 0.2047 - val_dense_58_loss: 0.0667 - val_dense_59_loss: 0.0021\n",
      "Epoch 7/50\n",
      "135278/135278 [==============================] - 281s - loss: 0.9387 - dense_54_loss: 0.0860 - dense_55_loss: 0.2886 - dense_56_loss: 0.2948 - dense_57_loss: 0.1941 - dense_58_loss: 0.0708 - dense_59_loss: 0.0043 - val_loss: 0.7468 - val_dense_54_loss: 0.0742 - val_dense_55_loss: 0.2360 - val_dense_56_loss: 0.2262 - val_dense_57_loss: 0.1572 - val_dense_58_loss: 0.0510 - val_dense_59_loss: 0.0021\n",
      "Epoch 8/50\n",
      "135278/135278 [==============================] - 311s - loss: 0.9429 - dense_54_loss: 0.0886 - dense_55_loss: 0.2895 - dense_56_loss: 0.2935 - dense_57_loss: 0.1982 - dense_58_loss: 0.0688 - dense_59_loss: 0.0043 - val_loss: 0.7477 - val_dense_54_loss: 0.0765 - val_dense_55_loss: 0.2362 - val_dense_56_loss: 0.2263 - val_dense_57_loss: 0.1544 - val_dense_58_loss: 0.0522 - val_dense_59_loss: 0.0021\n",
      "Epoch 9/50\n",
      "135278/135278 [==============================] - 294s - loss: 0.9408 - dense_54_loss: 0.0868 - dense_55_loss: 0.2916 - dense_56_loss: 0.2944 - dense_57_loss: 0.1935 - dense_58_loss: 0.0703 - dense_59_loss: 0.0043 - val_loss: 0.9520 - val_dense_54_loss: 0.0976 - val_dense_55_loss: 0.3141 - val_dense_56_loss: 0.2970 - val_dense_57_loss: 0.1798 - val_dense_58_loss: 0.0614 - val_dense_59_loss: 0.0021: - ETA: 228s - loss: 0.9408 - dense_54_loss: 0.0845 - dense_55_loss: 0.2889 - dense_56_loss: 0.2967 - de - ETA: 224s - loss: 0.9323 - dense_54_loss: 0.0838 - dense_55_loss: 0.2874 - dense_56_loss: 0.2919 - dense_57_loss: 0.1944 - dense_58_ - ETA: 198s - loss: 0.9386 - dense_54_loss: 0.0851 - dense_55_loss: 0.2905 - dense_56_loss: 0.2938 - dense_57_loss: 0.1935 - dense_58_loss: 0.0 - ETA: 196s - loss: 0.9382 - dense_54_loss: 0.0845 - dense_55_loss: 0.2912 - dense_56_loss: 0.2941 - dense_57_loss: 0.1930 - dense_ - ETA: 194s - loss: 0.9382 - dense_54_loss: 0.0843 - dense_5 - ETA: 175s - loss: 0.9481 - dense_54_loss: 0.0862 - dense_55_ - ETA: 19s - loss: 0.9406 - dense_54_loss: 0.0866 - dense_55_loss:  - ETA: 16s  - ETA: 1s - loss: 0.9403 - dense_54_loss: 0.0867 - dense_55_loss: 0.2916 - dense_56_loss: 0.2943 - dense_57_loss: 0.1932 - dense_58_loss: 0.0702 - dens\n",
      "Epoch 10/50\n",
      "135278/135278 [==============================] - 273s - loss: 0.9445 - dense_54_loss: 0.0881 - dense_55_loss: 0.2895 - dense_56_loss: 0.2957 - dense_57_loss: 0.1951 - dense_58_loss: 0.0718 - dense_59_loss: 0.0043 - val_loss: 0.9733 - val_dense_54_loss: 0.1315 - val_dense_55_loss: 0.2937 - val_dense_56_loss: 0.2864 - val_dense_57_loss: 0.1954 - val_dense_58_loss: 0.0641 - val_dense_59_loss: 0.0021\n",
      "Epoch 11/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9556 - dense_54_loss: 0.0895 - dense_55_loss: 0.2968 - dense_56_loss: 0.3000 - dense_57_loss: 0.1941 - dense_58_loss: 0.0709 - dense_59_loss: 0.0043 - val_loss: 0.7768 - val_dense_54_loss: 0.0796 - val_dense_55_loss: 0.2506 - val_dense_56_loss: 0.2339 - val_dense_57_loss: 0.1616 - val_dense_58_loss: 0.0489 - val_dense_59_loss: 0.0021\n",
      "Epoch 12/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9515 - dense_54_loss: 0.0868 - dense_55_loss: 0.2987 - dense_56_loss: 0.2970 - dense_57_loss: 0.1951 - dense_58_loss: 0.0697 - dense_59_loss: 0.0043 - val_loss: 0.7274 - val_dense_54_loss: 0.0798 - val_dense_55_loss: 0.2262 - val_dense_56_loss: 0.2191 - val_dense_57_loss: 0.1504 - val_dense_58_loss: 0.0497 - val_dense_59_loss: 0.0021\n",
      "Epoch 13/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9526 - dense_54_loss: 0.0885 - dense_55_loss: 0.2992 - dense_56_loss: 0.3006 - dense_57_loss: 0.1922 - dense_58_loss: 0.0677 - dense_59_loss: 0.0043 - val_loss: 0.7958 - val_dense_54_loss: 0.0780 - val_dense_55_loss: 0.2647 - val_dense_56_loss: 0.2400 - val_dense_57_loss: 0.1560 - val_dense_58_loss: 0.0550 - val_dense_59_loss: 0.0021\n",
      "Epoch 14/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9491 - dense_54_loss: 0.0893 - dense_55_loss: 0.2988 - dense_56_loss: 0.2960 - dense_57_loss: 0.1943 - dense_58_loss: 0.0664 - dense_59_loss: 0.0043 - val_loss: 0.8261 - val_dense_54_loss: 0.0833 - val_dense_55_loss: 0.2661 - val_dense_56_loss: 0.2611 - val_dense_57_loss: 0.1653 - val_dense_58_loss: 0.0482 - val_dense_59_loss: 0.0021\n",
      "Epoch 15/50\n",
      "135278/135278 [==============================] - 267s - loss: 0.9498 - dense_54_loss: 0.0891 - dense_55_loss: 0.3007 - dense_56_loss: 0.2959 - dense_57_loss: 0.1913 - dense_58_loss: 0.0686 - dense_59_loss: 0.0043 - val_loss: 0.7714 - val_dense_54_loss: 0.0768 - val_dense_55_loss: 0.2555 - val_dense_56_loss: 0.2362 - val_dense_57_loss: 0.1532 - val_dense_58_loss: 0.0477 - val_dense_59_loss: 0.0021\n",
      "Epoch 16/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9577 - dense_54_loss: 0.0905 - dense_55_loss: 0.2996 - dense_56_loss: 0.2991 - dense_57_loss: 0.1957 - dense_58_loss: 0.0684 - dense_59_loss: 0.0043 - val_loss: 0.8135 - val_dense_54_loss: 0.0886 - val_dense_55_loss: 0.2529 - val_dense_56_loss: 0.2524 - val_dense_57_loss: 0.1641 - val_dense_58_loss: 0.0533 - val_dense_59_loss: 0.0021\n",
      "Epoch 17/50\n",
      "135278/135278 [==============================] - 267s - loss: 0.9645 - dense_54_loss: 0.0910 - dense_55_loss: 0.3012 - dense_56_loss: 0.3015 - dense_57_loss: 0.1979 - dense_58_loss: 0.0686 - dense_59_loss: 0.0043 - val_loss: 0.8706 - val_dense_54_loss: 0.0970 - val_dense_55_loss: 0.2773 - val_dense_56_loss: 0.2627 - val_dense_57_loss: 0.1693 - val_dense_58_loss: 0.0623 - val_dense_59_loss: 0.0021\n",
      "Epoch 18/50\n",
      "135278/135278 [==============================] - 267s - loss: 0.9585 - dense_54_loss: 0.0907 - dense_55_loss: 0.2952 - dense_56_loss: 0.3019 - dense_57_loss: 0.1949 - dense_58_loss: 0.0715 - dense_59_loss: 0.0043 - val_loss: 0.8357 - val_dense_54_loss: 0.0842 - val_dense_55_loss: 0.2739 - val_dense_56_loss: 0.2576 - val_dense_57_loss: 0.1666 - val_dense_58_loss: 0.0513 - val_dense_59_loss: 0.0021\n",
      "Epoch 19/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9756 - dense_54_loss: 0.0942 - dense_55_loss: 0.3039 - dense_56_loss: 0.3081 - dense_57_loss: 0.1954 - dense_58_loss: 0.0698 - dense_59_loss: 0.0043 - val_loss: 0.9192 - val_dense_54_loss: 0.1219 - val_dense_55_loss: 0.2741 - val_dense_56_loss: 0.2642 - val_dense_57_loss: 0.1738 - val_dense_58_loss: 0.0830 - val_dense_59_loss: 0.0021\n",
      "Epoch 20/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9741 - dense_54_loss: 0.0931 - dense_55_loss: 0.3066 - dense_56_loss: 0.3051 - dense_57_loss: 0.1967 - dense_58_loss: 0.0683 - dense_59_loss: 0.0043 - val_loss: 0.7052 - val_dense_54_loss: 0.0678 - val_dense_55_loss: 0.2171 - val_dense_56_loss: 0.2175 - val_dense_57_loss: 0.1535 - val_dense_58_loss: 0.0472 - val_dense_59_loss: 0.0021\n",
      "Epoch 21/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0063 - dense_54_loss: 0.0980 - dense_55_loss: 0.3110 - dense_56_loss: 0.3162 - dense_57_loss: 0.2046 - dense_58_loss: 0.0723 - dense_59_loss: 0.0043 - val_loss: 0.8370 - val_dense_54_loss: 0.0881 - val_dense_55_loss: 0.2599 - val_dense_56_loss: 0.2666 - val_dense_57_loss: 0.1704 - val_dense_58_loss: 0.0499 - val_dense_59_loss: 0.0021\n",
      "Epoch 22/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0009 - dense_54_loss: 0.0963 - dense_55_loss: 0.3126 - dense_56_loss: 0.3143 - dense_57_loss: 0.2024 - dense_58_loss: 0.0710 - dense_59_loss: 0.0043 - val_loss: 0.8054 - val_dense_54_loss: 0.0934 - val_dense_55_loss: 0.2575 - val_dense_56_loss: 0.2378 - val_dense_57_loss: 0.1644 - val_dense_58_loss: 0.0501 - val_dense_59_loss: 0.0021\n",
      "Epoch 23/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0093 - dense_54_loss: 0.0974 - dense_55_loss: 0.3141 - dense_56_loss: 0.3170 - dense_57_loss: 0.2044 - dense_58_loss: 0.0722 - dense_59_loss: 0.0043 - val_loss: 0.8062 - val_dense_54_loss: 0.0808 - val_dense_55_loss: 0.2615 - val_dense_56_loss: 0.2504 - val_dense_57_loss: 0.1571 - val_dense_58_loss: 0.0543 - val_dense_59_loss: 0.0021\n",
      "Epoch 24/50\n",
      "135278/135278 [==============================] - 266s - loss: 0.9992 - dense_54_loss: 0.0961 - dense_55_loss: 0.3158 - dense_56_loss: 0.3126 - dense_57_loss: 0.1994 - dense_58_loss: 0.0711 - dense_59_loss: 0.0043 - val_loss: 0.8703 - val_dense_54_loss: 0.0941 - val_dense_55_loss: 0.2847 - val_dense_56_loss: 0.2649 - val_dense_57_loss: 0.1666 - val_dense_58_loss: 0.0579 - val_dense_59_loss: 0.0021\n",
      "Epoch 25/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0143 - dense_54_loss: 0.0985 - dense_55_loss: 0.3147 - dense_56_loss: 0.3215 - dense_57_loss: 0.2059 - dense_58_loss: 0.0695 - dense_59_loss: 0.0043 - val_loss: 0.8789 - val_dense_54_loss: 0.0892 - val_dense_55_loss: 0.2810 - val_dense_56_loss: 0.2745 - val_dense_57_loss: 0.1812 - val_dense_58_loss: 0.0509 - val_dense_59_loss: 0.0021\n",
      "Epoch 26/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0185 - dense_54_loss: 0.0987 - dense_55_loss: 0.3213 - dense_56_loss: 0.3187 - dense_57_loss: 0.2056 - dense_58_loss: 0.0700 - dense_59_loss: 0.0043 - val_loss: 0.8246 - val_dense_54_loss: 0.0823 - val_dense_55_loss: 0.2655 - val_dense_56_loss: 0.2633 - val_dense_57_loss: 0.1600 - val_dense_58_loss: 0.0514 - val_dense_59_loss: 0.0021\n",
      "Epoch 27/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0339 - dense_54_loss: 0.0990 - dense_55_loss: 0.3255 - dense_56_loss: 0.3265 - dense_57_loss: 0.2067 - dense_58_loss: 0.0719 - dense_59_loss: 0.0043 - val_loss: 0.9491 - val_dense_54_loss: 0.1215 - val_dense_55_loss: 0.2826 - val_dense_56_loss: 0.2874 - val_dense_57_loss: 0.1974 - val_dense_58_loss: 0.0581 - val_dense_59_loss: 0.0021\n",
      "Epoch 28/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0410 - dense_54_loss: 0.1018 - dense_55_loss: 0.3262 - dense_56_loss: 0.3269 - dense_57_loss: 0.2093 - dense_58_loss: 0.0726 - dense_59_loss: 0.0043 - val_loss: 0.8958 - val_dense_54_loss: 0.0916 - val_dense_55_loss: 0.2913 - val_dense_56_loss: 0.2770 - val_dense_57_loss: 0.1792 - val_dense_58_loss: 0.0545 - val_dense_59_loss: 0.0021\n",
      "Epoch 29/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0452 - dense_54_loss: 0.1045 - dense_55_loss: 0.3284 - dense_56_loss: 0.3271 - dense_57_loss: 0.2090 - dense_58_loss: 0.0719 - dense_59_loss: 0.0043 - val_loss: 0.8333 - val_dense_54_loss: 0.0890 - val_dense_55_loss: 0.2684 - val_dense_56_loss: 0.2516 - val_dense_57_loss: 0.1649 - val_dense_58_loss: 0.0573 - val_dense_59_loss: 0.0021\n",
      "Epoch 30/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0401 - dense_54_loss: 0.1027 - dense_55_loss: 0.3264 - dense_56_loss: 0.3264 - dense_57_loss: 0.2082 - dense_58_loss: 0.0721 - dense_59_loss: 0.0043 - val_loss: 0.9624 - val_dense_54_loss: 0.1195 - val_dense_55_loss: 0.3008 - val_dense_56_loss: 0.2959 - val_dense_57_loss: 0.1761 - val_dense_58_loss: 0.0679 - val_dense_59_loss: 0.0021\n",
      "Epoch 31/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0703 - dense_54_loss: 0.1067 - dense_55_loss: 0.3392 - dense_56_loss: 0.3374 - dense_57_loss: 0.2104 - dense_58_loss: 0.0723 - dense_59_loss: 0.0043 - val_loss: 0.8623 - val_dense_54_loss: 0.0902 - val_dense_55_loss: 0.2916 - val_dense_56_loss: 0.2635 - val_dense_57_loss: 0.1617 - val_dense_58_loss: 0.0531 - val_dense_59_loss: 0.0021\n",
      "Epoch 32/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0635 - dense_54_loss: 0.1035 - dense_55_loss: 0.3361 - dense_56_loss: 0.3343 - dense_57_loss: 0.2109 - dense_58_loss: 0.0745 - dense_59_loss: 0.0043 - val_loss: 0.8360 - val_dense_54_loss: 0.0841 - val_dense_55_loss: 0.2775 - val_dense_56_loss: 0.2625 - val_dense_57_loss: 0.1625 - val_dense_58_loss: 0.0473 - val_dense_59_loss: 0.0021\n",
      "Epoch 33/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0755 - dense_54_loss: 0.1063 - dense_55_loss: 0.3381 - dense_56_loss: 0.3385 - dense_57_loss: 0.2148 - dense_58_loss: 0.0735 - dense_59_loss: 0.0043 - val_loss: 0.8731 - val_dense_54_loss: 0.0976 - val_dense_55_loss: 0.2823 - val_dense_56_loss: 0.2701 - val_dense_57_loss: 0.1649 - val_dense_58_loss: 0.0560 - val_dense_59_loss: 0.0021\n",
      "Epoch 34/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0854 - dense_54_loss: 0.1065 - dense_55_loss: 0.3446 - dense_56_loss: 0.3373 - dense_57_loss: 0.2172 - dense_58_loss: 0.0755 - dense_59_loss: 0.0043 - val_loss: 0.8306 - val_dense_54_loss: 0.1036 - val_dense_55_loss: 0.2541 - val_dense_56_loss: 0.2507 - val_dense_57_loss: 0.1690 - val_dense_58_loss: 0.0511 - val_dense_59_loss: 0.0021\n",
      "Epoch 35/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.0990 - dense_54_loss: 0.1095 - dense_55_loss: 0.3452 - dense_56_loss: 0.3450 - dense_57_loss: 0.2216 - dense_58_loss: 0.0734 - dense_59_loss: 0.0043 - val_loss: 1.0128 - val_dense_54_loss: 0.1085 - val_dense_55_loss: 0.3324 - val_dense_56_loss: 0.3193 - val_dense_57_loss: 0.1842 - val_dense_58_loss: 0.0662 - val_dense_59_loss: 0.0021\n",
      "Epoch 36/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1073 - dense_54_loss: 0.1102 - dense_55_loss: 0.3497 - dense_56_loss: 0.3463 - dense_57_loss: 0.2200 - dense_58_loss: 0.0767 - dense_59_loss: 0.0043 - val_loss: 0.8641 - val_dense_54_loss: 0.1081 - val_dense_55_loss: 0.2582 - val_dense_56_loss: 0.2478 - val_dense_57_loss: 0.1826 - val_dense_58_loss: 0.0652 - val_dense_59_loss: 0.0021\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 266s - loss: 1.1155 - dense_54_loss: 0.1119 - dense_55_loss: 0.3495 - dense_56_loss: 0.3489 - dense_57_loss: 0.2231 - dense_58_loss: 0.0778 - dense_59_loss: 0.0043 - val_loss: 0.8413 - val_dense_54_loss: 0.0906 - val_dense_55_loss: 0.2715 - val_dense_56_loss: 0.2581 - val_dense_57_loss: 0.1683 - val_dense_58_loss: 0.0508 - val_dense_59_loss: 0.0021\n",
      "Epoch 38/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1266 - dense_54_loss: 0.1129 - dense_55_loss: 0.3523 - dense_56_loss: 0.3569 - dense_57_loss: 0.2236 - dense_58_loss: 0.0767 - dense_59_loss: 0.0043 - val_loss: 0.8572 - val_dense_54_loss: 0.0970 - val_dense_55_loss: 0.2682 - val_dense_56_loss: 0.2642 - val_dense_57_loss: 0.1694 - val_dense_58_loss: 0.0563 - val_dense_59_loss: 0.0021\n",
      "Epoch 39/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1280 - dense_54_loss: 0.1132 - dense_55_loss: 0.3555 - dense_56_loss: 0.3548 - dense_57_loss: 0.2227 - dense_58_loss: 0.0776 - dense_59_loss: 0.0043 - val_loss: 0.8025 - val_dense_54_loss: 0.0861 - val_dense_55_loss: 0.2479 - val_dense_56_loss: 0.2548 - val_dense_57_loss: 0.1637 - val_dense_58_loss: 0.0479 - val_dense_59_loss: 0.0021\n",
      "Epoch 40/50\n",
      "135278/135278 [==============================] - 267s - loss: 1.1400 - dense_54_loss: 0.1128 - dense_55_loss: 0.3603 - dense_56_loss: 0.3578 - dense_57_loss: 0.2281 - dense_58_loss: 0.0767 - dense_59_loss: 0.0043 - val_loss: 0.9996 - val_dense_54_loss: 0.1251 - val_dense_55_loss: 0.3104 - val_dense_56_loss: 0.3221 - val_dense_57_loss: 0.1825 - val_dense_58_loss: 0.0574 - val_dense_59_loss: 0.0021\n",
      "Epoch 41/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1594 - dense_54_loss: 0.1171 - dense_55_loss: 0.3673 - dense_56_loss: 0.3648 - dense_57_loss: 0.2287 - dense_58_loss: 0.0773 - dense_59_loss: 0.0043 - val_loss: 0.8427 - val_dense_54_loss: 0.0946 - val_dense_55_loss: 0.2653 - val_dense_56_loss: 0.2609 - val_dense_57_loss: 0.1704 - val_dense_58_loss: 0.0494 - val_dense_59_loss: 0.0021\n",
      "Epoch 42/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1722 - dense_54_loss: 0.1202 - dense_55_loss: 0.3660 - dense_56_loss: 0.3683 - dense_57_loss: 0.2314 - dense_58_loss: 0.0820 - dense_59_loss: 0.0043 - val_loss: 0.8245 - val_dense_54_loss: 0.0884 - val_dense_55_loss: 0.2634 - val_dense_56_loss: 0.2579 - val_dense_57_loss: 0.1672 - val_dense_58_loss: 0.0454 - val_dense_59_loss: 0.0021\n",
      "Epoch 43/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1580 - dense_54_loss: 0.1160 - dense_55_loss: 0.3662 - dense_56_loss: 0.3620 - dense_57_loss: 0.2319 - dense_58_loss: 0.0775 - dense_59_loss: 0.0043 - val_loss: 0.7864 - val_dense_54_loss: 0.0767 - val_dense_55_loss: 0.2577 - val_dense_56_loss: 0.2454 - val_dense_57_loss: 0.1579 - val_dense_58_loss: 0.0466 - val_dense_59_loss: 0.0021\n",
      "Epoch 44/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1598 - dense_54_loss: 0.1182 - dense_55_loss: 0.3623 - dense_56_loss: 0.3622 - dense_57_loss: 0.2312 - dense_58_loss: 0.0816 - dense_59_loss: 0.0043 - val_loss: 0.8744 - val_dense_54_loss: 0.0892 - val_dense_55_loss: 0.2747 - val_dense_56_loss: 0.2770 - val_dense_57_loss: 0.1741 - val_dense_58_loss: 0.0573 - val_dense_59_loss: 0.0021\n",
      "Epoch 45/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.1885 - dense_54_loss: 0.1194 - dense_55_loss: 0.3726 - dense_56_loss: 0.3705 - dense_57_loss: 0.2395 - dense_58_loss: 0.0821 - dense_59_loss: 0.0043 - val_loss: 0.9281 - val_dense_54_loss: 0.1017 - val_dense_55_loss: 0.3074 - val_dense_56_loss: 0.2859 - val_dense_57_loss: 0.1813 - val_dense_58_loss: 0.0496 - val_dense_59_loss: 0.0021\n",
      "Epoch 46/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.2020 - dense_54_loss: 0.1214 - dense_55_loss: 0.3784 - dense_56_loss: 0.3761 - dense_57_loss: 0.2400 - dense_58_loss: 0.0818 - dense_59_loss: 0.0043 - val_loss: 1.0428 - val_dense_54_loss: 0.1364 - val_dense_55_loss: 0.3223 - val_dense_56_loss: 0.3120 - val_dense_57_loss: 0.1934 - val_dense_58_loss: 0.0766 - val_dense_59_loss: 0.0021\n",
      "Epoch 47/50\n",
      "135278/135278 [==============================] - 266s - loss: 1.2070 - dense_54_loss: 0.1224 - dense_55_loss: 0.3784 - dense_56_loss: 0.3812 - dense_57_loss: 0.2388 - dense_58_loss: 0.0817 - dense_59_loss: 0.0043 - val_loss: 1.0427 - val_dense_54_loss: 0.1127 - val_dense_55_loss: 0.3539 - val_dense_56_loss: 0.3280 - val_dense_57_loss: 0.1919 - val_dense_58_loss: 0.0540 - val_dense_59_loss: 0.0021\n",
      "Epoch 48/50\n",
      "135278/135278 [==============================] - 8032s - loss: 1.2185 - dense_54_loss: 0.1221 - dense_55_loss: 0.3826 - dense_56_loss: 0.3816 - dense_57_loss: 0.2458 - dense_58_loss: 0.0822 - dense_59_loss: 0.0043 - val_loss: 0.8955 - val_dense_54_loss: 0.1015 - val_dense_55_loss: 0.2836 - val_dense_56_loss: 0.2774 - val_dense_57_loss: 0.1712 - val_dense_58_loss: 0.0596 - val_dense_59_loss: 0.0021\n",
      "Epoch 49/50\n",
      "135278/135278 [==============================] - 278s - loss: 1.2222 - dense_54_loss: 0.1222 - dense_55_loss: 0.3847 - dense_56_loss: 0.3858 - dense_57_loss: 0.2432 - dense_58_loss: 0.0820 - dense_59_loss: 0.0043 - val_loss: 0.9122 - val_dense_54_loss: 0.1023 - val_dense_55_loss: 0.2847 - val_dense_56_loss: 0.2806 - val_dense_57_loss: 0.1800 - val_dense_58_loss: 0.0624 - val_dense_59_loss: 0.0021\n",
      "Epoch 50/50\n",
      "135278/135278 [==============================] - 281s - loss: 1.2172 - dense_54_loss: 0.1217 - dense_55_loss: 0.3831 - dense_56_loss: 0.3838 - dense_57_loss: 0.2399 - dense_58_loss: 0.0844 - dense_59_loss: 0.0043 - val_loss: 0.9822 - val_dense_54_loss: 0.1063 - val_dense_55_loss: 0.3267 - val_dense_56_loss: 0.2899 - val_dense_57_loss: 0.1954 - val_dense_58_loss: 0.0617 - val_dense_59_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#training (50 epoch here)\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 50, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76103227351655589"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build cnn\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 7,7, activation='tanh', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 7,7, activation='tanh', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 7,7, activation='tanh', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 7,7, activation='tanh', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 7,7, activation='tanh', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='tanh')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/50\n",
      "135278/135278 [==============================] - 736s - loss: 4.1654 - dense_2_loss: 0.3800 - dense_3_loss: 1.3210 - dense_4_loss: 1.5122 - dense_5_loss: 0.7790 - dense_6_loss: 0.1608 - dense_7_loss: 0.0124 - val_loss: 2.7427 - val_dense_2_loss: 0.2182 - val_dense_3_loss: 0.8313 - val_dense_4_loss: 0.9927 - val_dense_5_loss: 0.5739 - val_dense_6_loss: 0.1242 - val_dense_7_loss: 0.0024\n",
      "Epoch 2/50\n",
      "135278/135278 [==============================] - 718s - loss: 2.3851 - dense_2_loss: 0.1968 - dense_3_loss: 0.7065 - dense_4_loss: 0.8278 - dense_5_loss: 0.5227 - dense_6_loss: 0.1278 - dense_7_loss: 0.0035 - val_loss: 1.9378 - val_dense_2_loss: 0.1544 - val_dense_3_loss: 0.5950 - val_dense_4_loss: 0.6487 - val_dense_5_loss: 0.4297 - val_dense_6_loss: 0.1085 - val_dense_7_loss: 0.0015\n",
      "Epoch 3/50\n",
      "135278/135278 [==============================] - 718s - loss: 1.7561 - dense_2_loss: 0.1432 - dense_3_loss: 0.5180 - dense_4_loss: 0.5869 - dense_5_loss: 0.3955 - dense_6_loss: 0.1098 - dense_7_loss: 0.0028 - val_loss: 1.5813 - val_dense_2_loss: 0.1491 - val_dense_3_loss: 0.4681 - val_dense_4_loss: 0.5062 - val_dense_5_loss: 0.3562 - val_dense_6_loss: 0.1004 - val_dense_7_loss: 0.0014\n",
      "Epoch 4/50\n",
      "135278/135278 [==============================] - 709s - loss: 1.3776 - dense_2_loss: 0.1089 - dense_3_loss: 0.4085 - dense_4_loss: 0.4490 - dense_5_loss: 0.3122 - dense_6_loss: 0.0965 - dense_7_loss: 0.0024 - val_loss: 1.2612 - val_dense_2_loss: 0.1030 - val_dense_3_loss: 0.3733 - val_dense_4_loss: 0.4209 - val_dense_5_loss: 0.2782 - val_dense_6_loss: 0.0847 - val_dense_7_loss: 9.8031e-04\n",
      "Epoch 5/50\n",
      "135278/135278 [==============================] - 692s - loss: 1.1047 - dense_2_loss: 0.0847 - dense_3_loss: 0.3301 - dense_4_loss: 0.3523 - dense_5_loss: 0.2497 - dense_6_loss: 0.0856 - dense_7_loss: 0.0023 - val_loss: 1.1172 - val_dense_2_loss: 0.0918 - val_dense_3_loss: 0.3364 - val_dense_4_loss: 0.3571 - val_dense_5_loss: 0.2524 - val_dense_6_loss: 0.0785 - val_dense_7_loss: 0.0011\n",
      "Epoch 6/50\n",
      "135278/135278 [==============================] - 693s - loss: 0.9002 - dense_2_loss: 0.0659 - dense_3_loss: 0.2736 - dense_4_loss: 0.2810 - dense_5_loss: 0.2015 - dense_6_loss: 0.0758 - dense_7_loss: 0.0023 - val_loss: 0.9710 - val_dense_2_loss: 0.0929 - val_dense_3_loss: 0.2918 - val_dense_4_loss: 0.3039 - val_dense_5_loss: 0.2109 - val_dense_6_loss: 0.0706 - val_dense_7_loss: 9.7362e-04\n",
      "Epoch 7/50\n",
      "135278/135278 [==============================] - 704s - loss: 0.7391 - dense_2_loss: 0.0532 - dense_3_loss: 0.2259 - dense_4_loss: 0.2265 - dense_5_loss: 0.1633 - dense_6_loss: 0.0683 - dense_7_loss: 0.0019 - val_loss: 0.8344 - val_dense_2_loss: 0.0692 - val_dense_3_loss: 0.2483 - val_dense_4_loss: 0.2653 - val_dense_5_loss: 0.1863 - val_dense_6_loss: 0.0647 - val_dense_7_loss: 5.8183e-04\n",
      "Epoch 8/50\n",
      "135278/135278 [==============================] - 700s - loss: 0.6243 - dense_2_loss: 0.0444 - dense_3_loss: 0.1931 - dense_4_loss: 0.1884 - dense_5_loss: 0.1347 - dense_6_loss: 0.0617 - dense_7_loss: 0.0020 - val_loss: 0.8064 - val_dense_2_loss: 0.0763 - val_dense_3_loss: 0.2453 - val_dense_4_loss: 0.2501 - val_dense_5_loss: 0.1736 - val_dense_6_loss: 0.0605 - val_dense_7_loss: 5.2692e-04\n",
      "Epoch 9/50\n",
      "135278/135278 [==============================] - 694s - loss: 0.5256 - dense_2_loss: 0.0374 - dense_3_loss: 0.1642 - dense_4_loss: 0.1550 - dense_5_loss: 0.1117 - dense_6_loss: 0.0557 - dense_7_loss: 0.0017 - val_loss: 0.8350 - val_dense_2_loss: 0.0921 - val_dense_3_loss: 0.2375 - val_dense_4_loss: 0.2645 - val_dense_5_loss: 0.1814 - val_dense_6_loss: 0.0592 - val_dense_7_loss: 4.2120e-04\n",
      "Epoch 10/50\n",
      "135278/135278 [==============================] - 696s - loss: 0.4551 - dense_2_loss: 0.0320 - dense_3_loss: 0.1421 - dense_4_loss: 0.1337 - dense_5_loss: 0.0950 - dense_6_loss: 0.0507 - dense_7_loss: 0.0016 - val_loss: 0.7125 - val_dense_2_loss: 0.0634 - val_dense_3_loss: 0.2203 - val_dense_4_loss: 0.2247 - val_dense_5_loss: 0.1480 - val_dense_6_loss: 0.0555 - val_dense_7_loss: 6.2545e-04\n",
      "Epoch 11/50\n",
      "135278/135278 [==============================] - 696s - loss: 0.3974 - dense_2_loss: 0.0280 - dense_3_loss: 0.1255 - dense_4_loss: 0.1152 - dense_5_loss: 0.0812 - dense_6_loss: 0.0459 - dense_7_loss: 0.0015 - val_loss: 0.6127 - val_dense_2_loss: 0.0532 - val_dense_3_loss: 0.1856 - val_dense_4_loss: 0.1940 - val_dense_5_loss: 0.1306 - val_dense_6_loss: 0.0489 - val_dense_7_loss: 5.0573e-04\n",
      "Epoch 12/50\n",
      "135278/135278 [==============================] - 696s - loss: 0.3536 - dense_2_loss: 0.0258 - dense_3_loss: 0.1120 - dense_4_loss: 0.1017 - dense_5_loss: 0.0703 - dense_6_loss: 0.0423 - dense_7_loss: 0.0014 - val_loss: 0.6913 - val_dense_2_loss: 0.0845 - val_dense_3_loss: 0.1953 - val_dense_4_loss: 0.2023 - val_dense_5_loss: 0.1570 - val_dense_6_loss: 0.0518 - val_dense_7_loss: 5.0352e-04\n",
      "Epoch 13/50\n",
      "135278/135278 [==============================] - 700s - loss: 0.3147 - dense_2_loss: 0.0231 - dense_3_loss: 0.1009 - dense_4_loss: 0.0896 - dense_5_loss: 0.0618 - dense_6_loss: 0.0379 - dense_7_loss: 0.0013 - val_loss: 0.6300 - val_dense_2_loss: 0.0680 - val_dense_3_loss: 0.1824 - val_dense_4_loss: 0.1917 - val_dense_5_loss: 0.1399 - val_dense_6_loss: 0.0474 - val_dense_7_loss: 5.3367e-04\n",
      "Epoch 14/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.2887 - dense_2_loss: 0.0222 - dense_3_loss: 0.0927 - dense_4_loss: 0.0813 - dense_5_loss: 0.0559 - dense_6_loss: 0.0353 - dense_7_loss: 0.0013 - val_loss: 0.6536 - val_dense_2_loss: 0.0705 - val_dense_3_loss: 0.2032 - val_dense_4_loss: 0.1930 - val_dense_5_loss: 0.1443 - val_dense_6_loss: 0.0423 - val_dense_7_loss: 4.3244e-04\n",
      "Epoch 15/50\n",
      "135278/135278 [==============================] - 720s - loss: 0.2594 - dense_2_loss: 0.0200 - dense_3_loss: 0.0823 - dense_4_loss: 0.0744 - dense_5_loss: 0.0497 - dense_6_loss: 0.0319 - dense_7_loss: 0.0011 - val_loss: 0.5849 - val_dense_2_loss: 0.0577 - val_dense_3_loss: 0.1748 - val_dense_4_loss: 0.1930 - val_dense_5_loss: 0.1186 - val_dense_6_loss: 0.0404 - val_dense_7_loss: 3.7519e-04\n",
      "Epoch 16/50\n",
      "135278/135278 [==============================] - 714s - loss: 0.2415 - dense_2_loss: 0.0183 - dense_3_loss: 0.0779 - dense_4_loss: 0.0699 - dense_5_loss: 0.0456 - dense_6_loss: 0.0288 - dense_7_loss: 0.0011 - val_loss: 0.6125 - val_dense_2_loss: 0.0654 - val_dense_3_loss: 0.1844 - val_dense_4_loss: 0.1999 - val_dense_5_loss: 0.1228 - val_dense_6_loss: 0.0395 - val_dense_7_loss: 3.6164e-04\n",
      "Epoch 17/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.2267 - dense_2_loss: 0.0173 - dense_3_loss: 0.0746 - dense_4_loss: 0.0647 - dense_5_loss: 0.0426 - dense_6_loss: 0.0265 - dense_7_loss: 0.0012 - val_loss: 0.5808 - val_dense_2_loss: 0.0556 - val_dense_3_loss: 0.1791 - val_dense_4_loss: 0.1868 - val_dense_5_loss: 0.1218 - val_dense_6_loss: 0.0367 - val_dense_7_loss: 6.7373e-04\n",
      "Epoch 18/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.2128 - dense_2_loss: 0.0167 - dense_3_loss: 0.0700 - dense_4_loss: 0.0604 - dense_5_loss: 0.0399 - dense_6_loss: 0.0248 - dense_7_loss: 9.8610e-04 - val_loss: 0.5248 - val_dense_2_loss: 0.0557 - val_dense_3_loss: 0.1569 - val_dense_4_loss: 0.1676 - val_dense_5_loss: 0.1079 - val_dense_6_loss: 0.0364 - val_dense_7_loss: 2.8858e-04\n",
      "Epoch 19/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.2036 - dense_2_loss: 0.0156 - dense_3_loss: 0.0678 - dense_4_loss: 0.0589 - dense_5_loss: 0.0378 - dense_6_loss: 0.0226 - dense_7_loss: 8.8142e-04 - val_loss: 0.5492 - val_dense_2_loss: 0.0597 - val_dense_3_loss: 0.1679 - val_dense_4_loss: 0.1729 - val_dense_5_loss: 0.1125 - val_dense_6_loss: 0.0358 - val_dense_7_loss: 3.8788e-04\n",
      "Epoch 20/50\n",
      "    96/135278 [..............................] - ETA: 2734s - loss: 0.1533 - dense_2_loss: 0.0194 - dense_3_loss: 0.0356 - dense_4_loss: 0.0479 - dense_5_loss: 0.0220 - dense_6_loss: 0.0283 - dense_7_loss: 5.7045e-05  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryau1\\Anaconda3\\lib\\site-packages\\keras-1.2.0-py3.5.egg\\keras\\callbacks.py:70: UserWarning: Method on_batch_end() is slow compared to the batch update (0.150605). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 715s - loss: 0.1927 - dense_2_loss: 0.0160 - dense_3_loss: 0.0623 - dense_4_loss: 0.0565 - dense_5_loss: 0.0362 - dense_6_loss: 0.0209 - dense_7_loss: 8.6938e-04 - val_loss: 0.5602 - val_dense_2_loss: 0.0611 - val_dense_3_loss: 0.1630 - val_dense_4_loss: 0.1804 - val_dense_5_loss: 0.1189 - val_dense_6_loss: 0.0365 - val_dense_7_loss: 2.7982e-04\n",
      "Epoch 21/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1895 - dense_2_loss: 0.0158 - dense_3_loss: 0.0628 - dense_4_loss: 0.0557 - dense_5_loss: 0.0350 - dense_6_loss: 0.0194 - dense_7_loss: 8.5764e-04 - val_loss: 0.5380 - val_dense_2_loss: 0.0590 - val_dense_3_loss: 0.1584 - val_dense_4_loss: 0.1694 - val_dense_5_loss: 0.1162 - val_dense_6_loss: 0.0347 - val_dense_7_loss: 3.6448e-04\n",
      "Epoch 22/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1786 - dense_2_loss: 0.0138 - dense_3_loss: 0.0594 - dense_4_loss: 0.0540 - dense_5_loss: 0.0319 - dense_6_loss: 0.0185 - dense_7_loss: 8.7268e-04 - val_loss: 0.5518 - val_dense_2_loss: 0.0589 - val_dense_3_loss: 0.1568 - val_dense_4_loss: 0.1840 - val_dense_5_loss: 0.1146 - val_dense_6_loss: 0.0371 - val_dense_7_loss: 3.5237e-04\n",
      "Epoch 23/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1712 - dense_2_loss: 0.0138 - dense_3_loss: 0.0576 - dense_4_loss: 0.0499 - dense_5_loss: 0.0316 - dense_6_loss: 0.0174 - dense_7_loss: 9.4641e-04 - val_loss: 0.5435 - val_dense_2_loss: 0.0599 - val_dense_3_loss: 0.1537 - val_dense_4_loss: 0.1800 - val_dense_5_loss: 0.1192 - val_dense_6_loss: 0.0303 - val_dense_7_loss: 3.7260e-04\n",
      "Epoch 24/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1688 - dense_2_loss: 0.0143 - dense_3_loss: 0.0571 - dense_4_loss: 0.0497 - dense_5_loss: 0.0305 - dense_6_loss: 0.0164 - dense_7_loss: 8.1469e-04 - val_loss: 0.5308 - val_dense_2_loss: 0.0580 - val_dense_3_loss: 0.1559 - val_dense_4_loss: 0.1742 - val_dense_5_loss: 0.1085 - val_dense_6_loss: 0.0339 - val_dense_7_loss: 3.0786e-04\n",
      "Epoch 25/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1613 - dense_2_loss: 0.0133 - dense_3_loss: 0.0541 - dense_4_loss: 0.0487 - dense_5_loss: 0.0289 - dense_6_loss: 0.0154 - dense_7_loss: 8.4263e-04 - val_loss: 0.5374 - val_dense_2_loss: 0.0619 - val_dense_3_loss: 0.1543 - val_dense_4_loss: 0.1782 - val_dense_5_loss: 0.1097 - val_dense_6_loss: 0.0330 - val_dense_7_loss: 2.1754e-04\n",
      "Epoch 26/50\n",
      "135278/135278 [==============================] - 711s - loss: 0.1572 - dense_2_loss: 0.0126 - dense_3_loss: 0.0542 - dense_4_loss: 0.0471 - dense_5_loss: 0.0282 - dense_6_loss: 0.0143 - dense_7_loss: 7.2966e-04 - val_loss: 0.5219 - val_dense_2_loss: 0.0626 - val_dense_3_loss: 0.1491 - val_dense_4_loss: 0.1602 - val_dense_5_loss: 0.1170 - val_dense_6_loss: 0.0328 - val_dense_7_loss: 1.9711e-04\n",
      "Epoch 27/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1513 - dense_2_loss: 0.0128 - dense_3_loss: 0.0510 - dense_4_loss: 0.0461 - dense_5_loss: 0.0270 - dense_6_loss: 0.0137 - dense_7_loss: 7.0674e-04 - val_loss: 0.5722 - val_dense_2_loss: 0.0698 - val_dense_3_loss: 0.1567 - val_dense_4_loss: 0.1839 - val_dense_5_loss: 0.1238 - val_dense_6_loss: 0.0378 - val_dense_7_loss: 1.9081e-04\n",
      "Epoch 28/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1509 - dense_2_loss: 0.0126 - dense_3_loss: 0.0508 - dense_4_loss: 0.0461 - dense_5_loss: 0.0275 - dense_6_loss: 0.0133 - dense_7_loss: 5.8103e-04 - val_loss: 0.5526 - val_dense_2_loss: 0.0667 - val_dense_3_loss: 0.1584 - val_dense_4_loss: 0.1815 - val_dense_5_loss: 0.1161 - val_dense_6_loss: 0.0298 - val_dense_7_loss: 1.9841e-04\n",
      "Epoch 29/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1446 - dense_2_loss: 0.0122 - dense_3_loss: 0.0487 - dense_4_loss: 0.0435 - dense_5_loss: 0.0269 - dense_6_loss: 0.0126 - dense_7_loss: 6.9930e-04 - val_loss: 0.5411 - val_dense_2_loss: 0.0595 - val_dense_3_loss: 0.1564 - val_dense_4_loss: 0.1761 - val_dense_5_loss: 0.1187 - val_dense_6_loss: 0.0302 - val_dense_7_loss: 1.7023e-04\n",
      "Epoch 30/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1452 - dense_2_loss: 0.0120 - dense_3_loss: 0.0503 - dense_4_loss: 0.0446 - dense_5_loss: 0.0260 - dense_6_loss: 0.0117 - dense_7_loss: 6.0187e-04 - val_loss: 0.5351 - val_dense_2_loss: 0.0552 - val_dense_3_loss: 0.1542 - val_dense_4_loss: 0.1815 - val_dense_5_loss: 0.1141 - val_dense_6_loss: 0.0300 - val_dense_7_loss: 1.3719e-04\n",
      "Epoch 31/50\n",
      "135278/135278 [==============================] - 713s - loss: 0.1411 - dense_2_loss: 0.0115 - dense_3_loss: 0.0487 - dense_4_loss: 0.0435 - dense_5_loss: 0.0248 - dense_6_loss: 0.0120 - dense_7_loss: 6.8224e-04 - val_loss: 0.5226 - val_dense_2_loss: 0.0555 - val_dense_3_loss: 0.1549 - val_dense_4_loss: 0.1720 - val_dense_5_loss: 0.1116 - val_dense_6_loss: 0.0285 - val_dense_7_loss: 1.6563e-04\n",
      "Epoch 32/50\n",
      "135278/135278 [==============================] - 711s - loss: 0.1407 - dense_2_loss: 0.0114 - dense_3_loss: 0.0473 - dense_4_loss: 0.0443 - dense_5_loss: 0.0255 - dense_6_loss: 0.0116 - dense_7_loss: 6.3096e-04 - val_loss: 0.5412 - val_dense_2_loss: 0.0620 - val_dense_3_loss: 0.1538 - val_dense_4_loss: 0.1802 - val_dense_5_loss: 0.1180 - val_dense_6_loss: 0.0270 - val_dense_7_loss: 1.7162e-04\n",
      "Epoch 33/50\n",
      "135278/135278 [==============================] - 711s - loss: 0.1346 - dense_2_loss: 0.0107 - dense_3_loss: 0.0454 - dense_4_loss: 0.0420 - dense_5_loss: 0.0248 - dense_6_loss: 0.0109 - dense_7_loss: 6.8302e-04 - val_loss: 0.5159 - val_dense_2_loss: 0.0596 - val_dense_3_loss: 0.1477 - val_dense_4_loss: 0.1741 - val_dense_5_loss: 0.1068 - val_dense_6_loss: 0.0275 - val_dense_7_loss: 2.0096e-04\n",
      "Epoch 34/50\n",
      "135278/135278 [==============================] - 712s - loss: 0.1353 - dense_2_loss: 0.0111 - dense_3_loss: 0.0456 - dense_4_loss: 0.0426 - dense_5_loss: 0.0246 - dense_6_loss: 0.0107 - dense_7_loss: 6.4911e-04 - val_loss: 0.5614 - val_dense_2_loss: 0.0718 - val_dense_3_loss: 0.1542 - val_dense_4_loss: 0.1929 - val_dense_5_loss: 0.1147 - val_dense_6_loss: 0.0275 - val_dense_7_loss: 2.2369e-04\n",
      "Epoch 35/50\n",
      "135278/135278 [==============================] - 708s - loss: 0.1361 - dense_2_loss: 0.0118 - dense_3_loss: 0.0474 - dense_4_loss: 0.0407 - dense_5_loss: 0.0252 - dense_6_loss: 0.0105 - dense_7_loss: 5.6173e-04 - val_loss: 0.6104 - val_dense_2_loss: 0.0821 - val_dense_3_loss: 0.1755 - val_dense_4_loss: 0.1919 - val_dense_5_loss: 0.1222 - val_dense_6_loss: 0.0385 - val_dense_7_loss: 1.7633e-04\n",
      "Epoch 36/50\n",
      "135278/135278 [==============================] - 705s - loss: 0.1343 - dense_2_loss: 0.0112 - dense_3_loss: 0.0464 - dense_4_loss: 0.0418 - dense_5_loss: 0.0243 - dense_6_loss: 0.0101 - dense_7_loss: 5.5571e-04 - val_loss: 0.5602 - val_dense_2_loss: 0.0748 - val_dense_3_loss: 0.1581 - val_dense_4_loss: 0.1799 - val_dense_5_loss: 0.1152 - val_dense_6_loss: 0.0321 - val_dense_7_loss: 2.5269e-04\n",
      "Epoch 37/50\n",
      "135278/135278 [==============================] - 705s - loss: 0.1302 - dense_2_loss: 0.0111 - dense_3_loss: 0.0449 - dense_4_loss: 0.0405 - dense_5_loss: 0.0233 - dense_6_loss: 0.0098 - dense_7_loss: 5.7583e-04 - val_loss: 0.5603 - val_dense_2_loss: 0.0703 - val_dense_3_loss: 0.1614 - val_dense_4_loss: 0.1848 - val_dense_5_loss: 0.1162 - val_dense_6_loss: 0.0271 - val_dense_7_loss: 3.6846e-04\n",
      "Epoch 38/50\n",
      "135278/135278 [==============================] - 704s - loss: 0.1256 - dense_2_loss: 0.0111 - dense_3_loss: 0.0433 - dense_4_loss: 0.0393 - dense_5_loss: 0.0220 - dense_6_loss: 0.0094 - dense_7_loss: 5.0469e-04 - val_loss: 0.5305 - val_dense_2_loss: 0.0635 - val_dense_3_loss: 0.1531 - val_dense_4_loss: 0.1693 - val_dense_5_loss: 0.1160 - val_dense_6_loss: 0.0283 - val_dense_7_loss: 3.2617e-04\n",
      "Epoch 39/50\n",
      "135278/135278 [==============================] - 704s - loss: 0.1258 - dense_2_loss: 0.0104 - dense_3_loss: 0.0452 - dense_4_loss: 0.0397 - dense_5_loss: 0.0210 - dense_6_loss: 0.0089 - dense_7_loss: 4.8029e-04 - val_loss: 0.5289 - val_dense_2_loss: 0.0646 - val_dense_3_loss: 0.1440 - val_dense_4_loss: 0.1778 - val_dense_5_loss: 0.1117 - val_dense_6_loss: 0.0305 - val_dense_7_loss: 2.8743e-04\n",
      "Epoch 40/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1221 - dense_2_loss: 0.0093 - dense_3_loss: 0.0429 - dense_4_loss: 0.0379 - dense_5_loss: 0.0227 - dense_6_loss: 0.0089 - dense_7_loss: 5.4680e-04 - val_loss: 0.5460 - val_dense_2_loss: 0.0633 - val_dense_3_loss: 0.1570 - val_dense_4_loss: 0.1871 - val_dense_5_loss: 0.1106 - val_dense_6_loss: 0.0277 - val_dense_7_loss: 3.2570e-04\n",
      "Epoch 41/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1223 - dense_2_loss: 0.0109 - dense_3_loss: 0.0424 - dense_4_loss: 0.0373 - dense_5_loss: 0.0224 - dense_6_loss: 0.0089 - dense_7_loss: 4.8120e-04 - val_loss: 0.5655 - val_dense_2_loss: 0.0638 - val_dense_3_loss: 0.1613 - val_dense_4_loss: 0.1902 - val_dense_5_loss: 0.1225 - val_dense_6_loss: 0.0274 - val_dense_7_loss: 2.5403e-04\n",
      "Epoch 42/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1221 - dense_2_loss: 0.0103 - dense_3_loss: 0.0425 - dense_4_loss: 0.0372 - dense_5_loss: 0.0226 - dense_6_loss: 0.0090 - dense_7_loss: 5.1335e-04 - val_loss: 0.5310 - val_dense_2_loss: 0.0587 - val_dense_3_loss: 0.1541 - val_dense_4_loss: 0.1820 - val_dense_5_loss: 0.1085 - val_dense_6_loss: 0.0276 - val_dense_7_loss: 1.3924e-04\n",
      "Epoch 43/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1166 - dense_2_loss: 0.0102 - dense_3_loss: 0.0403 - dense_4_loss: 0.0372 - dense_5_loss: 0.0204 - dense_6_loss: 0.0079 - dense_7_loss: 4.4044e-04 - val_loss: 0.5279 - val_dense_2_loss: 0.0644 - val_dense_3_loss: 0.1497 - val_dense_4_loss: 0.1719 - val_dense_5_loss: 0.1134 - val_dense_6_loss: 0.0283 - val_dense_7_loss: 1.5503e-04\n",
      "Epoch 44/50\n",
      "135278/135278 [==============================] - 705s - loss: 0.1195 - dense_2_loss: 0.0104 - dense_3_loss: 0.0414 - dense_4_loss: 0.0381 - dense_5_loss: 0.0211 - dense_6_loss: 0.0082 - dense_7_loss: 3.9701e-04 - val_loss: 0.5568 - val_dense_2_loss: 0.0653 - val_dense_3_loss: 0.1690 - val_dense_4_loss: 0.1854 - val_dense_5_loss: 0.1104 - val_dense_6_loss: 0.0265 - val_dense_7_loss: 2.3490e-04\n",
      "Epoch 45/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1196 - dense_2_loss: 0.0098 - dense_3_loss: 0.0418 - dense_4_loss: 0.0375 - dense_5_loss: 0.0219 - dense_6_loss: 0.0083 - dense_7_loss: 4.3088e-04 - val_loss: 0.5515 - val_dense_2_loss: 0.0596 - val_dense_3_loss: 0.1643 - val_dense_4_loss: 0.1862 - val_dense_5_loss: 0.1129 - val_dense_6_loss: 0.0282 - val_dense_7_loss: 3.8984e-04\n",
      "Epoch 46/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1168 - dense_2_loss: 0.0103 - dense_3_loss: 0.0412 - dense_4_loss: 0.0368 - dense_5_loss: 0.0200 - dense_6_loss: 0.0079 - dense_7_loss: 5.3904e-04 - val_loss: 0.5510 - val_dense_2_loss: 0.0666 - val_dense_3_loss: 0.1615 - val_dense_4_loss: 0.1768 - val_dense_5_loss: 0.1195 - val_dense_6_loss: 0.0265 - val_dense_7_loss: 1.2310e-04\n",
      "Epoch 47/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1152 - dense_2_loss: 0.0103 - dense_3_loss: 0.0396 - dense_4_loss: 0.0365 - dense_5_loss: 0.0205 - dense_6_loss: 0.0078 - dense_7_loss: 4.1770e-04 - val_loss: 0.5910 - val_dense_2_loss: 0.0665 - val_dense_3_loss: 0.1827 - val_dense_4_loss: 0.1886 - val_dense_5_loss: 0.1254 - val_dense_6_loss: 0.0278 - val_dense_7_loss: 1.2090e-04\n",
      "Epoch 48/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1143 - dense_2_loss: 0.0101 - dense_3_loss: 0.0405 - dense_4_loss: 0.0356 - dense_5_loss: 0.0205 - dense_6_loss: 0.0071 - dense_7_loss: 4.8709e-04 - val_loss: 0.5370 - val_dense_2_loss: 0.0608 - val_dense_3_loss: 0.1638 - val_dense_4_loss: 0.1752 - val_dense_5_loss: 0.1126 - val_dense_6_loss: 0.0244 - val_dense_7_loss: 1.3262e-04\n",
      "Epoch 49/50\n",
      "135278/135278 [==============================] - 706s - loss: 0.1148 - dense_2_loss: 0.0095 - dense_3_loss: 0.0412 - dense_4_loss: 0.0358 - dense_5_loss: 0.0202 - dense_6_loss: 0.0078 - dense_7_loss: 3.8210e-04 - val_loss: 0.5525 - val_dense_2_loss: 0.0666 - val_dense_3_loss: 0.1630 - val_dense_4_loss: 0.1755 - val_dense_5_loss: 0.1194 - val_dense_6_loss: 0.0279 - val_dense_7_loss: 1.0278e-04\n",
      "Epoch 50/50\n",
      "135278/135278 [==============================] - 707s - loss: 0.1151 - dense_2_loss: 0.0102 - dense_3_loss: 0.0392 - dense_4_loss: 0.0373 - dense_5_loss: 0.0208 - dense_6_loss: 0.0072 - dense_7_loss: 3.9227e-04 - val_loss: 0.5706 - val_dense_2_loss: 0.0713 - val_dense_3_loss: 0.1712 - val_dense_4_loss: 0.1819 - val_dense_5_loss: 0.1179 - val_dense_6_loss: 0.0282 - val_dense_7_loss: 1.4083e-04\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 50, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89335967906113412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save model weights for evaluation\n",
    "weights = model.get_weights()\n",
    "np.save('final_model_weight.npy', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load and use real test set to check accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13068, 62)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.load('test_labels.npy')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13068, 54, 54, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img as train data\n",
    "size = labels.shape[0]\n",
    "numsample = 5\n",
    "folder = 'test/croppedtight/'\n",
    "images = []\n",
    "\n",
    "for i in range(size):\n",
    "    im = Image.open(folder+str(i+1)+'tight.png')\n",
    "    images.append(np.asarray(im))\n",
    "        \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70684113865932052"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.predict(images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 54, 54, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 54, 54, 64)    9472        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 27, 27, 64)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 27, 27, 64)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 27, 27, 128)   401536      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 13, 13, 128)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 13, 13, 128)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 13, 13, 192)   1204416     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 6, 6, 192)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 6, 6, 192)     0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 6, 6, 256)     2408704     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 3, 3, 256)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 3, 3, 256)     0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 3, 3, 256)     3211520     dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 1, 1, 256)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1, 1, 256)     0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 256)           0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           32896       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 7)             903         dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 11)            1419        dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 7,276,542\n",
      "Trainable params: 7,276,542\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

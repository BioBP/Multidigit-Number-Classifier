{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Dropout, Flatten, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33402, 62)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training label\n",
    "labels = np.load('labels.npy')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 54, 54, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img as train data\n",
    "size = labels.shape[0]\n",
    "numsample = 5\n",
    "folder = 'train/croppedsampled/'\n",
    "images = []\n",
    "\n",
    "for k in range(numsample):\n",
    "    for i in range(size):\n",
    "        im = Image.open(folder+str(i+1)+'_'+str(k)+'.png')\n",
    "        images.append(np.asarray(im))\n",
    "        \n",
    "images = np.array(images)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167010, 62)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replicate labels to cover all sample\n",
    "labels = np.tile(labels,(5,1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split training set and validation set\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.1, random_state=0)\n",
    "train_index, test_index = next(rs.split(images)) #just 1\n",
    "test_images = images[test_index]\n",
    "test_labels = labels[test_index]\n",
    "images = images[train_index]\n",
    "labels = labels[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initial model (same as initial model in other program)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/20\n",
      "135278/135278 [==============================] - 280s - loss: 5.3096 - dense_23_loss: 0.5698 - dense_24_loss: 1.6628 - dense_25_loss: 1.9013 - dense_26_loss: 0.9621 - dense_27_loss: 0.1930 - dense_28_loss: 0.0206 - val_loss: 3.6351 - val_dense_23_loss: 0.3500 - val_dense_24_loss: 1.0782 - val_dense_25_loss: 1.2932 - val_dense_26_loss: 0.7632 - val_dense_27_loss: 0.1490 - val_dense_28_loss: 0.0015\n",
      "Epoch 2/20\n",
      "135278/135278 [==============================] - 281s - loss: 3.1299 - dense_23_loss: 0.2591 - dense_24_loss: 0.9263 - dense_25_loss: 1.1297 - dense_26_loss: 0.6660 - dense_27_loss: 0.1453 - dense_28_loss: 0.0036 - val_loss: 2.3032 - val_dense_23_loss: 0.1819 - val_dense_24_loss: 0.6794 - val_dense_25_loss: 0.8002 - val_dense_26_loss: 0.5197 - val_dense_27_loss: 0.1202 - val_dense_28_loss: 0.0017\n",
      "Epoch 3/20\n",
      "135278/135278 [==============================] - 270s - loss: 2.3538 - dense_23_loss: 0.1981 - dense_24_loss: 0.6773 - dense_25_loss: 0.8151 - dense_26_loss: 0.5285 - dense_27_loss: 0.1307 - dense_28_loss: 0.0041 - val_loss: 1.8507 - val_dense_23_loss: 0.1574 - val_dense_24_loss: 0.5464 - val_dense_25_loss: 0.6246 - val_dense_26_loss: 0.4104 - val_dense_27_loss: 0.1100 - val_dense_28_loss: 0.0018\n",
      "Epoch 4/20\n",
      "135278/135278 [==============================] - 274s - loss: 1.9399 - dense_23_loss: 0.1670 - dense_24_loss: 0.5593 - dense_25_loss: 0.6527 - dense_26_loss: 0.4338 - dense_27_loss: 0.1230 - dense_28_loss: 0.0041 - val_loss: 1.5365 - val_dense_23_loss: 0.1418 - val_dense_24_loss: 0.4410 - val_dense_25_loss: 0.5053 - val_dense_26_loss: 0.3434 - val_dense_27_loss: 0.1027 - val_dense_28_loss: 0.0021\n",
      "Epoch 5/20\n",
      "135278/135278 [==============================] - 281s - loss: 1.6941 - dense_23_loss: 0.1466 - dense_24_loss: 0.4922 - dense_25_loss: 0.5615 - dense_26_loss: 0.3740 - dense_27_loss: 0.1157 - dense_28_loss: 0.0042 - val_loss: 1.3911 - val_dense_23_loss: 0.1385 - val_dense_24_loss: 0.3803 - val_dense_25_loss: 0.4556 - val_dense_26_loss: 0.3072 - val_dense_27_loss: 0.1074 - val_dense_28_loss: 0.0021\n",
      "Epoch 6/20\n",
      "135278/135278 [==============================] - 274s - loss: 1.5205 - dense_23_loss: 0.1331 - dense_24_loss: 0.4384 - dense_25_loss: 0.4998 - dense_26_loss: 0.3359 - dense_27_loss: 0.1091 - dense_28_loss: 0.0042 - val_loss: 1.2782 - val_dense_23_loss: 0.1271 - val_dense_24_loss: 0.3581 - val_dense_25_loss: 0.4151 - val_dense_26_loss: 0.2773 - val_dense_27_loss: 0.0984 - val_dense_28_loss: 0.0021\n",
      "Epoch 7/20\n",
      "135278/135278 [==============================] - 272s - loss: 1.3926 - dense_23_loss: 0.1207 - dense_24_loss: 0.4060 - dense_25_loss: 0.4542 - dense_26_loss: 0.3045 - dense_27_loss: 0.1030 - dense_28_loss: 0.0043 - val_loss: 1.3031 - val_dense_23_loss: 0.1356 - val_dense_24_loss: 0.3652 - val_dense_25_loss: 0.4242 - val_dense_26_loss: 0.2748 - val_dense_27_loss: 0.1012 - val_dense_28_loss: 0.0022\n",
      "Epoch 8/20\n",
      "135278/135278 [==============================] - 272s - loss: 1.3118 - dense_23_loss: 0.1137 - dense_24_loss: 0.3823 - dense_25_loss: 0.4253 - dense_26_loss: 0.2858 - dense_27_loss: 0.1006 - dense_28_loss: 0.0041 - val_loss: 1.1499 - val_dense_23_loss: 0.1087 - val_dense_24_loss: 0.3452 - val_dense_25_loss: 0.3604 - val_dense_26_loss: 0.2459 - val_dense_27_loss: 0.0876 - val_dense_28_loss: 0.0021\n",
      "Epoch 9/20\n",
      "135278/135278 [==============================] - 270s - loss: 1.2353 - dense_23_loss: 0.1078 - dense_24_loss: 0.3578 - dense_25_loss: 0.4007 - dense_26_loss: 0.2685 - dense_27_loss: 0.0965 - dense_28_loss: 0.0041 - val_loss: 1.1288 - val_dense_23_loss: 0.1250 - val_dense_24_loss: 0.3137 - val_dense_25_loss: 0.3603 - val_dense_26_loss: 0.2403 - val_dense_27_loss: 0.0874 - val_dense_28_loss: 0.0021\n",
      "Epoch 10/20\n",
      "135278/135278 [==============================] - 271s - loss: 1.1782 - dense_23_loss: 0.1033 - dense_24_loss: 0.3436 - dense_25_loss: 0.3760 - dense_26_loss: 0.2561 - dense_27_loss: 0.0950 - dense_28_loss: 0.0042 - val_loss: 0.9731 - val_dense_23_loss: 0.1021 - val_dense_24_loss: 0.2775 - val_dense_25_loss: 0.2992 - val_dense_26_loss: 0.2130 - val_dense_27_loss: 0.0791 - val_dense_28_loss: 0.0021\n",
      "Epoch 11/20\n",
      "135278/135278 [==============================] - 276s - loss: 1.1312 - dense_23_loss: 0.0984 - dense_24_loss: 0.3322 - dense_25_loss: 0.3591 - dense_26_loss: 0.2459 - dense_27_loss: 0.0914 - dense_28_loss: 0.0043 - val_loss: 1.0158 - val_dense_23_loss: 0.1079 - val_dense_24_loss: 0.2908 - val_dense_25_loss: 0.3097 - val_dense_26_loss: 0.2168 - val_dense_27_loss: 0.0885 - val_dense_28_loss: 0.0021\n",
      "Epoch 12/20\n",
      "135278/135278 [==============================] - 283s - loss: 1.0948 - dense_23_loss: 0.0979 - dense_24_loss: 0.3218 - dense_25_loss: 0.3478 - dense_26_loss: 0.2345 - dense_27_loss: 0.0884 - dense_28_loss: 0.0042 - val_loss: 0.9716 - val_dense_23_loss: 0.0925 - val_dense_24_loss: 0.2918 - val_dense_25_loss: 0.3064 - val_dense_26_loss: 0.2027 - val_dense_27_loss: 0.0761 - val_dense_28_loss: 0.0021\n",
      "Epoch 13/20\n",
      "135278/135278 [==============================] - 273s - loss: 1.0584 - dense_23_loss: 0.0927 - dense_24_loss: 0.3112 - dense_25_loss: 0.3379 - dense_26_loss: 0.2266 - dense_27_loss: 0.0858 - dense_28_loss: 0.0043 - val_loss: 0.8933 - val_dense_23_loss: 0.0891 - val_dense_24_loss: 0.2610 - val_dense_25_loss: 0.2742 - val_dense_26_loss: 0.1947 - val_dense_27_loss: 0.0721 - val_dense_28_loss: 0.0021\n",
      "Epoch 14/20\n",
      "135278/135278 [==============================] - 275s - loss: 1.0403 - dense_23_loss: 0.0922 - dense_24_loss: 0.3065 - dense_25_loss: 0.3325 - dense_26_loss: 0.2189 - dense_27_loss: 0.0859 - dense_28_loss: 0.0043 - val_loss: 0.9022 - val_dense_23_loss: 0.0888 - val_dense_24_loss: 0.2680 - val_dense_25_loss: 0.2891 - val_dense_26_loss: 0.1871 - val_dense_27_loss: 0.0669 - val_dense_28_loss: 0.0021\n",
      "Epoch 15/20\n",
      "135278/135278 [==============================] - 273s - loss: 1.0196 - dense_23_loss: 0.0908 - dense_24_loss: 0.3006 - dense_25_loss: 0.3235 - dense_26_loss: 0.2175 - dense_27_loss: 0.0829 - dense_28_loss: 0.0043 - val_loss: 0.9266 - val_dense_23_loss: 0.0998 - val_dense_24_loss: 0.2785 - val_dense_25_loss: 0.2885 - val_dense_26_loss: 0.1871 - val_dense_27_loss: 0.0706 - val_dense_28_loss: 0.0021\n",
      "Epoch 16/20\n",
      "135278/135278 [==============================] - 270s - loss: 0.9964 - dense_23_loss: 0.0881 - dense_24_loss: 0.2952 - dense_25_loss: 0.3144 - dense_26_loss: 0.2125 - dense_27_loss: 0.0818 - dense_28_loss: 0.0043 - val_loss: 0.8397 - val_dense_23_loss: 0.0892 - val_dense_24_loss: 0.2433 - val_dense_25_loss: 0.2596 - val_dense_26_loss: 0.1770 - val_dense_27_loss: 0.0685 - val_dense_28_loss: 0.0021\n",
      "Epoch 17/20\n",
      "135278/135278 [==============================] - 273s - loss: 0.9870 - dense_23_loss: 0.0865 - dense_24_loss: 0.2940 - dense_25_loss: 0.3131 - dense_26_loss: 0.2082 - dense_27_loss: 0.0810 - dense_28_loss: 0.0043 - val_loss: 0.8206 - val_dense_23_loss: 0.0843 - val_dense_24_loss: 0.2406 - val_dense_25_loss: 0.2481 - val_dense_26_loss: 0.1814 - val_dense_27_loss: 0.0641 - val_dense_28_loss: 0.0021\n",
      "Epoch 18/20\n",
      "135278/135278 [==============================] - 284s - loss: 0.9713 - dense_23_loss: 0.0858 - dense_24_loss: 0.2899 - dense_25_loss: 0.3053 - dense_26_loss: 0.2051 - dense_27_loss: 0.0810 - dense_28_loss: 0.0043 - val_loss: 0.8590 - val_dense_23_loss: 0.0970 - val_dense_24_loss: 0.2486 - val_dense_25_loss: 0.2664 - val_dense_26_loss: 0.1796 - val_dense_27_loss: 0.0652 - val_dense_28_loss: 0.0021\n",
      "Epoch 19/20\n",
      "135278/135278 [==============================] - 269s - loss: 0.9596 - dense_23_loss: 0.0877 - dense_24_loss: 0.2868 - dense_25_loss: 0.3019 - dense_26_loss: 0.1997 - dense_27_loss: 0.0793 - dense_28_loss: 0.0043 - val_loss: 0.8122 - val_dense_23_loss: 0.0882 - val_dense_24_loss: 0.2415 - val_dense_25_loss: 0.2478 - val_dense_26_loss: 0.1720 - val_dense_27_loss: 0.0605 - val_dense_28_loss: 0.0021\n",
      "Epoch 20/20\n",
      "135278/135278 [==============================] - 271s - loss: 0.9546 - dense_23_loss: 0.0845 - dense_24_loss: 0.2857 - dense_25_loss: 0.3003 - dense_26_loss: 0.2005 - dense_27_loss: 0.0792 - dense_28_loss: 0.0043 - val_loss: 0.9406 - val_dense_23_loss: 0.1182 - val_dense_24_loss: 0.2609 - val_dense_25_loss: 0.2935 - val_dense_26_loss: 0.1842 - val_dense_27_loss: 0.0816 - val_dense_28_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 20, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74929644931441231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning rate = 0.001 (instead of 0.0001 in initial model)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/10\n",
      "135278/135278 [==============================] - 310s - loss: 4.7522 - dense_2_loss: 0.5240 - dense_3_loss: 1.4588 - dense_4_loss: 1.6471 - dense_5_loss: 0.9272 - dense_6_loss: 0.1853 - dense_7_loss: 0.0098 - val_loss: 2.9573 - val_dense_2_loss: 0.2653 - val_dense_3_loss: 0.9328 - val_dense_4_loss: 1.0257 - val_dense_5_loss: 0.6041 - val_dense_6_loss: 0.1272 - val_dense_7_loss: 0.0021\n",
      "Epoch 2/10\n",
      "135278/135278 [==============================] - 299s - loss: 3.3170 - dense_2_loss: 0.3253 - dense_3_loss: 0.9992 - dense_4_loss: 1.1527 - dense_5_loss: 0.6712 - dense_6_loss: 0.1642 - dense_7_loss: 0.0043 - val_loss: 2.8598 - val_dense_2_loss: 0.2616 - val_dense_3_loss: 0.9117 - val_dense_4_loss: 0.9863 - val_dense_5_loss: 0.5589 - val_dense_6_loss: 0.1392 - val_dense_7_loss: 0.0021\n",
      "Epoch 3/10\n",
      "135278/135278 [==============================] - 311s - loss: 3.3261 - dense_2_loss: 0.3363 - dense_3_loss: 1.0060 - dense_4_loss: 1.1424 - dense_5_loss: 0.6684 - dense_6_loss: 0.1687 - dense_7_loss: 0.0042 - val_loss: 2.9866 - val_dense_2_loss: 0.3000 - val_dense_3_loss: 0.9297 - val_dense_4_loss: 1.0375 - val_dense_5_loss: 0.5740 - val_dense_6_loss: 0.1432 - val_dense_7_loss: 0.002116 - dense_5_loss: 0.6675 - dense_6_loss: 0.1688 - dense_7_l - ETA: 6s - loss: 3.3253 - dense_2_loss: 0.3364 - dense_3_loss: 1.0054 - dens\n",
      "Epoch 4/10\n",
      "135278/135278 [==============================] - 305s - loss: 3.4713 - dense_2_loss: 0.3570 - dense_3_loss: 1.0613 - dense_4_loss: 1.1859 - dense_5_loss: 0.6876 - dense_6_loss: 0.1754 - dense_7_loss: 0.0042 - val_loss: 2.8306 - val_dense_2_loss: 0.2747 - val_dense_3_loss: 0.8585 - val_dense_4_loss: 0.9708 - val_dense_5_loss: 0.5759 - val_dense_6_loss: 0.1485 - val_dense_7_loss: 0.0021\n",
      "Epoch 5/10\n",
      "135278/135278 [==============================] - 289s - loss: 3.5928 - dense_2_loss: 0.3682 - dense_3_loss: 1.1158 - dense_4_loss: 1.2239 - dense_5_loss: 0.7006 - dense_6_loss: 0.1801 - dense_7_loss: 0.0042 - val_loss: 2.9460 - val_dense_2_loss: 0.2949 - val_dense_3_loss: 0.9188 - val_dense_4_loss: 1.0250 - val_dense_5_loss: 0.5667 - val_dense_6_loss: 0.1388 - val_dense_7_loss: 0.0019\n",
      "Epoch 6/10\n",
      "135278/135278 [==============================] - 280s - loss: 3.7689 - dense_2_loss: 0.3923 - dense_3_loss: 1.1709 - dense_4_loss: 1.2921 - dense_5_loss: 0.7273 - dense_6_loss: 0.1820 - dense_7_loss: 0.0042 - val_loss: 3.3250 - val_dense_2_loss: 0.3689 - val_dense_3_loss: 0.9682 - val_dense_4_loss: 1.1158 - val_dense_5_loss: 0.7087 - val_dense_6_loss: 0.1613 - val_dense_7_loss: 0.0021\n",
      "Epoch 7/10\n",
      "135278/135278 [==============================] - 326s - loss: 3.9379 - dense_2_loss: 0.4110 - dense_3_loss: 1.2307 - dense_4_loss: 1.3473 - dense_5_loss: 0.7568 - dense_6_loss: 0.1879 - dense_7_loss: 0.0042 - val_loss: 3.9073 - val_dense_2_loss: 0.4149 - val_dense_3_loss: 1.2328 - val_dense_4_loss: 1.3968 - val_dense_5_loss: 0.7021 - val_dense_6_loss: 0.1585 - val_dense_7_loss: 0.0021\n",
      "Epoch 8/10\n",
      "135278/135278 [==============================] - 349s - loss: 4.1781 - dense_2_loss: 0.4532 - dense_3_loss: 1.3075 - dense_4_loss: 1.4334 - dense_5_loss: 0.7871 - dense_6_loss: 0.1927 - dense_7_loss: 0.0042 - val_loss: 3.4625 - val_dense_2_loss: 0.3416 - val_dense_3_loss: 1.0896 - val_dense_4_loss: 1.1955 - val_dense_5_loss: 0.6811 - val_dense_6_loss: 0.1526 - val_dense_7_loss: 0.0021\n",
      "Epoch 9/10\n",
      "135278/135278 [==============================] - 294s - loss: 4.1699 - dense_2_loss: 0.4430 - dense_3_loss: 1.3097 - dense_4_loss: 1.4215 - dense_5_loss: 0.7925 - dense_6_loss: 0.1989 - dense_7_loss: 0.0043 - val_loss: 3.9924 - val_dense_2_loss: 0.4264 - val_dense_3_loss: 1.2237 - val_dense_4_loss: 1.4359 - val_dense_5_loss: 0.7495 - val_dense_6_loss: 0.1547 - val_dense_7_loss: 0.0021\n",
      "Epoch 10/10\n",
      "135278/135278 [==============================] - 272s - loss: 4.2560 - dense_2_loss: 0.4552 - dense_3_loss: 1.3365 - dense_4_loss: 1.4623 - dense_5_loss: 0.8014 - dense_6_loss: 0.1964 - dense_7_loss: 0.0043 - val_loss: 3.0907 - val_dense_2_loss: 0.2898 - val_dense_3_loss: 0.9546 - val_dense_4_loss: 1.0582 - val_dense_5_loss: 0.6428 - val_dense_6_loss: 0.1431 - val_dense_7_loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 10, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33045925393689002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning rate = 0.0005 (instead of 0.0001 in initial model)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/10\n",
      "135278/135278 [==============================] - 287s - loss: 4.3449 - dense_9_loss: 0.5281 - dense_10_loss: 1.3172 - dense_11_loss: 1.5075 - dense_12_loss: 0.8045 - dense_13_loss: 0.1751 - dense_14_loss: 0.0125 - val_loss: 2.3975 - val_dense_9_loss: 0.2293 - val_dense_10_loss: 0.7184 - val_dense_11_loss: 0.8035 - val_dense_12_loss: 0.5244 - val_dense_13_loss: 0.1198 - val_dense_14_loss: 0.0021\n",
      "Epoch 2/10\n",
      "135278/135278 [==============================] - 277s - loss: 2.3714 - dense_9_loss: 0.2273 - dense_10_loss: 0.7010 - dense_11_loss: 0.7964 - dense_12_loss: 0.5017 - dense_13_loss: 0.1407 - dense_14_loss: 0.0043 - val_loss: 1.7284 - val_dense_9_loss: 0.1636 - val_dense_10_loss: 0.5074 - val_dense_11_loss: 0.5720 - val_dense_12_loss: 0.3715 - val_dense_13_loss: 0.1118 - val_dense_14_loss: 0.0021\n",
      "Epoch 3/10\n",
      "135278/135278 [==============================] - 286s - loss: 2.1431 - dense_9_loss: 0.2116 - dense_10_loss: 0.6337 - dense_11_loss: 0.7051 - dense_12_loss: 0.4525 - dense_13_loss: 0.1359 - dense_14_loss: 0.0043 - val_loss: 1.8245 - val_dense_9_loss: 0.1838 - val_dense_10_loss: 0.5511 - val_dense_11_loss: 0.6020 - val_dense_12_loss: 0.3756 - val_dense_13_loss: 0.1098 - val_dense_14_loss: 0.0021\n",
      "Epoch 4/10\n",
      "135278/135278 [==============================] - 322s - loss: 2.1003 - dense_9_loss: 0.2092 - dense_10_loss: 0.6197 - dense_11_loss: 0.6904 - dense_12_loss: 0.4405 - dense_13_loss: 0.1363 - dense_14_loss: 0.0043 - val_loss: 1.7640 - val_dense_9_loss: 0.1861 - val_dense_10_loss: 0.4908 - val_dense_11_loss: 0.5949 - val_dense_12_loss: 0.3820 - val_dense_13_loss: 0.1081 - val_dense_14_loss: 0.0021\n",
      "Epoch 5/10\n",
      "135278/135278 [==============================] - 308s - loss: 2.1201 - dense_9_loss: 0.2149 - dense_10_loss: 0.6270 - dense_11_loss: 0.6931 - dense_12_loss: 0.4447 - dense_13_loss: 0.1361 - dense_14_loss: 0.0043 - val_loss: 1.9521 - val_dense_9_loss: 0.1946 - val_dense_10_loss: 0.6095 - val_dense_11_loss: 0.6508 - val_dense_12_loss: 0.3879 - val_dense_13_loss: 0.1073 - val_dense_14_loss: 0.0021\n",
      "Epoch 6/10\n",
      "135278/135278 [==============================] - 304s - loss: 2.2029 - dense_9_loss: 0.2276 - dense_10_loss: 0.6553 - dense_11_loss: 0.7160 - dense_12_loss: 0.4575 - dense_13_loss: 0.1422 - dense_14_loss: 0.0043 - val_loss: 1.5930 - val_dense_9_loss: 0.1691 - val_dense_10_loss: 0.4615 - val_dense_11_loss: 0.5151 - val_dense_12_loss: 0.3384 - val_dense_13_loss: 0.1068 - val_dense_14_loss: 0.0021\n",
      "Epoch 7/10\n",
      "135278/135278 [==============================] - 281s - loss: 2.2994 - dense_9_loss: 0.2410 - dense_10_loss: 0.6861 - dense_11_loss: 0.7485 - dense_12_loss: 0.4736 - dense_13_loss: 0.1459 - dense_14_loss: 0.0043 - val_loss: 1.6333 - val_dense_9_loss: 0.1637 - val_dense_10_loss: 0.4854 - val_dense_11_loss: 0.5352 - val_dense_12_loss: 0.3431 - val_dense_13_loss: 0.1037 - val_dense_14_loss: 0.0021\n",
      "Epoch 8/10\n",
      "135278/135278 [==============================] - 319s - loss: 2.3941 - dense_9_loss: 0.2523 - dense_10_loss: 0.7179 - dense_11_loss: 0.7807 - dense_12_loss: 0.4876 - dense_13_loss: 0.1514 - dense_14_loss: 0.0043 - val_loss: 1.7337 - val_dense_9_loss: 0.1748 - val_dense_10_loss: 0.5448 - val_dense_11_loss: 0.5571 - val_dense_12_loss: 0.3473 - val_dense_13_loss: 0.1076 - val_dense_14_loss: 0.0021\n",
      "Epoch 9/10\n",
      "135278/135278 [==============================] - 288s - loss: 2.4606 - dense_9_loss: 0.2578 - dense_10_loss: 0.7431 - dense_11_loss: 0.8073 - dense_12_loss: 0.5002 - dense_13_loss: 0.1479 - dense_14_loss: 0.0042 - val_loss: 1.9360 - val_dense_9_loss: 0.1861 - val_dense_10_loss: 0.5872 - val_dense_11_loss: 0.6602 - val_dense_12_loss: 0.3923 - val_dense_13_loss: 0.1080 - val_dense_14_loss: 0.0021- dense_12_loss: 0.4921 - dense_13_ - ETA: 93s - loss: 2.4331 - dense_9_loss: 0.2519 - dense_10_loss: 0.7352 - dense_11_loss: 0.8019 - dense_12_loss: 0.4924 - dense_13_loss: 0.1472 - de - ETA: 92s - loss: 2.4378 - dense_9_loss: 0.2530 - dense_10_loss: 0.7371 - dense_11_loss: 0.8030 - dense_12_loss: 0.4930 - dense_13_loss: 0.1469 - dense_14_loss: 0.00 - ETA: 92s - loss: 2.4383 - dense_9_loss: 0.2531 - dense_10_loss: 0.7370 - dense_11_loss: 0.8033 - dense_12_ - ETA: 88s - loss: 2.4365 - dense_9_loss: 0.2536 - dense_10_loss: 0.7362 - dense_11_loss: 0.8022 - dense_12 - ETA: 84s - loss: 2.4365 - dense_9_loss: 0.2535 - dense_10_loss: 0.7358 - dense_11_loss: 0.8030 - dense_12_loss: 0.4922 - dense_13_loss: 0.1474 - dense_14_ - ETA: 83s - loss: 2.4385 - dense_9_loss: 0.2543 - dense_10_loss: 0.7361 - dense_11_loss: 0.8032 - dense_12_loss: 0.492 - ETA: 80s - loss: 2.4383 - ETA: 71s - loss: 2.4434 - dense_9_loss: 0.2550 - dense_10_loss: 0.7365 - dense_11_loss: 0.8062 - dense_12_loss: 0.4944 - dense_13_loss: 0.1469 - - ETA: 69s - loss: 2.4459 - dense_9_loss: 0.2552 - dense_10_loss: 0.7375 - dense_11_loss: 0.8067 - dense_12_loss: 0.4950 - ETA: 66s - loss: 2.4453 - dense_9_loss: 0.2551 - dense_10_loss: 0.7377 - dense_11_loss: 0.8060 - dense_12_l - ETA: 51s - loss: 2.4446 - dense_9_loss: 0.2545 - dense_10_loss: 0.7369 - dense_11_loss: 0.8051 - dense_12_loss: 0.4970 -  - ETA: 48s - loss: 2. - ETA: 39s - loss: 2.4488 - dense_9_loss: 0.2542 - dense_10_loss: 0.7393 - dense_11 - ETA: 33s - loss: 2.4488 - dense_9_loss: 0.2545 - dense_10_loss: 0.7401 - dense_11_loss: 0.8049 - dense_12_loss: 0.4985 - dense_13 - ETA: 31s - loss: 2.4495 - dense_9_loss: 0.2547 - dense_10_loss: 0.7399 - dense_11_loss: 0.8055 - dense_12_loss: 0. - ETA: 27s - loss: 2.4504 - dense_9_loss: 0.2549 - dense_10_l - ETA: 20s - loss: 2.4531 - dense_9_loss: 0.2557 - dense_10_loss: 0.7404 - dense_11_loss: 0.8054 - dense_12_loss: 0.4994 - dense_13_loss: 0.1479 - dense_14_loss: 0.004 - ETA: 20s - loss: 2.4530 - dense_9_loss: 0.2557 - dense_10_loss: 0.7404 - dense_11_loss: 0.8054 - dense_12_loss: 0.4993 - dense_13_loss:  - ETA: 8s - loss: 2.4584 - dense_9_loss: 0.2570 - dense_10_loss: 0.7425 - dense_11_loss: 0.8068 - dense_12_loss: 0.5000 - dense_1 - ETA: 7s - loss: 2.4581 - dense_9_loss: 0.2569 - dense_10_loss: 0.7425 - dense_11_loss: 0.8066 - dense_12_loss: 0.5000 - - ETA: 6s - loss: 2.4576 - dense_9_loss: 0.2569 - dense_10_loss: 0.7421 - dense_11_loss: 0.8066 - dense_12_loss: 0.4997 - dense_13_loss: 0.1479 - dense_14_ - ETA: 5s - loss: 2.4577 - dense_9_loss: 0.2568 - dense_10_loss: 0.7424 - dense_11_loss: 0.8066 - dense_12_loss: 0.4998 - d - ETA: 4s - loss: 2.4587 - dense_9_lo\n",
      "Epoch 10/10\n",
      "135278/135278 [==============================] - 289s - loss: 2.5460 - dense_9_loss: 0.2681 - dense_10_loss: 0.7743 - dense_11_loss: 0.8319 - dense_12_loss: 0.5105 - dense_13_loss: 0.1569 - dense_14_loss: 0.0043 - val_loss: 1.8262 - val_dense_9_loss: 0.2237 - val_dense_10_loss: 0.5149 - val_dense_11_loss: 0.6224 - val_dense_12_loss: 0.3460 - val_dense_13_loss: 0.1171 - val_dense_14_loss: 0.0021 0.8214 - dense_12_loss: 0.5153 - ETA: 167s - loss: 2.5420 - dense_9_loss: 0.2693 - dense_10_loss: 0.7724 - dense_11_loss: 0.8214 - dense_12_ - ETA: 165s - loss: 2.5419 - dense_9_loss: 0.2695 - dense_10_loss: 0.7724 - dense_11_loss: 0.82\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 10, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58768935991856774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning rate = 0.00005 (instead of 0.0001 in initial model)\n",
    "a = Input(shape=(54, 54, 3))\n",
    "#conv layer\n",
    "c1 = Conv2D(64, 3,3, activation='relu', border_mode='same')(a)\n",
    "c1p = MaxPooling2D(pool_size=(2, 2)) (c1)\n",
    "c1d = Dropout(0.1)(c1p)\n",
    "\n",
    "c2 = Conv2D(128, 3,3, activation='relu', border_mode='same')(c1d)\n",
    "c2p = MaxPooling2D(pool_size=(2, 2)) (c2)\n",
    "c2d = Dropout(0.1)(c2p)\n",
    "\n",
    "c3 = Conv2D(192, 3,3, activation='relu', border_mode='same')(c2d)\n",
    "c3p = MaxPooling2D(pool_size=(2, 2)) (c3)\n",
    "c3d = Dropout(0.1)(c3p)\n",
    "\n",
    "\n",
    "c4 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c3d)\n",
    "c4p = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "c4d = Dropout(0.1)(c4p)\n",
    "\n",
    "\n",
    "c5 = Conv2D(256, 3,3, activation='relu', border_mode='same')(c4d)\n",
    "c5p = MaxPooling2D(pool_size=(2, 2)) (c5)\n",
    "c5d = Dropout(0.1)(c5p)\n",
    "\n",
    "#linear layer\n",
    "flat = Flatten()(c5d)\n",
    "d1 = Dense(128, activation='relu')(flat)\n",
    "d1d = Dropout(0.1)(d1)\n",
    "\n",
    "#output\n",
    "o_length = Dense(7, activation='softmax')(d1d)\n",
    "o_digit1 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit2 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit3 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit4 = Dense(11, activation='softmax')(d1d)\n",
    "o_digit5 = Dense(11, activation='softmax')(d1d)\n",
    "model = Model(a, [o_length,o_digit1,o_digit2,o_digit3,o_digit4,o_digit5])\n",
    "\n",
    "rms = RMSprop(lr=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135278 samples, validate on 15031 samples\n",
      "Epoch 1/20\n",
      "135278/135278 [==============================] - 296s - loss: 6.6242 - dense_2_loss: 0.8377 - dense_3_loss: 2.0854 - dense_4_loss: 2.2692 - dense_5_loss: 1.1439 - dense_6_loss: 0.2586 - dense_7_loss: 0.0295 - val_loss: 5.3667 - val_dense_2_loss: 0.5023 - val_dense_3_loss: 1.7528 - val_dense_4_loss: 1.9422 - val_dense_5_loss: 0.9543 - val_dense_6_loss: 0.2091 - val_dense_7_loss: 0.0059\n",
      "Epoch 2/20\n",
      "135278/135278 [==============================] - 278s - loss: 4.6692 - dense_2_loss: 0.4085 - dense_3_loss: 1.4931 - dense_4_loss: 1.7441 - dense_5_loss: 0.8542 - dense_6_loss: 0.1658 - dense_7_loss: 0.0034 - val_loss: 3.6948 - val_dense_2_loss: 0.3065 - val_dense_3_loss: 1.1494 - val_dense_4_loss: 1.3782 - val_dense_5_loss: 0.7210 - val_dense_6_loss: 0.1385 - val_dense_7_loss: 0.0011\n",
      "Epoch 3/20\n",
      "135278/135278 [==============================] - 277s - loss: 3.5843 - dense_2_loss: 0.2928 - dense_3_loss: 1.0944 - dense_4_loss: 1.3205 - dense_5_loss: 0.7215 - dense_6_loss: 0.1514 - dense_7_loss: 0.0036 - val_loss: 2.8051 - val_dense_2_loss: 0.2070 - val_dense_3_loss: 0.8456 - val_dense_4_loss: 1.0238 - val_dense_5_loss: 0.5992 - val_dense_6_loss: 0.1282 - val_dense_7_loss: 0.0014\n",
      "Epoch 4/20\n",
      "135278/135278 [==============================] - 272s - loss: 2.9237 - dense_2_loss: 0.2366 - dense_3_loss: 0.8695 - dense_4_loss: 1.0469 - dense_5_loss: 0.6263 - dense_6_loss: 0.1405 - dense_7_loss: 0.0039 - val_loss: 2.2842 - val_dense_2_loss: 0.1787 - val_dense_3_loss: 0.6693 - val_dense_4_loss: 0.8018 - val_dense_5_loss: 0.5131 - val_dense_6_loss: 0.1197 - val_dense_7_loss: 0.0016\n",
      "Epoch 5/20\n",
      "135278/135278 [==============================] - 269s - loss: 2.4844 - dense_2_loss: 0.2023 - dense_3_loss: 0.7275 - dense_4_loss: 0.8701 - dense_5_loss: 0.5489 - dense_6_loss: 0.1315 - dense_7_loss: 0.0041 - val_loss: 1.9649 - val_dense_2_loss: 0.1490 - val_dense_3_loss: 0.5702 - val_dense_4_loss: 0.6792 - val_dense_5_loss: 0.4532 - val_dense_6_loss: 0.1115 - val_dense_7_loss: 0.0018\n",
      "Epoch 6/20\n",
      "135278/135278 [==============================] - 276s - loss: 2.1814 - dense_2_loss: 0.1782 - dense_3_loss: 0.6340 - dense_4_loss: 0.7508 - dense_5_loss: 0.4890 - dense_6_loss: 0.1252 - dense_7_loss: 0.0041 - val_loss: 1.7853 - val_dense_2_loss: 0.1512 - val_dense_3_loss: 0.5139 - val_dense_4_loss: 0.5895 - val_dense_5_loss: 0.4163 - val_dense_6_loss: 0.1124 - val_dense_7_loss: 0.0020\n",
      "Epoch 7/20\n",
      "135278/135278 [==============================] - 284s - loss: 1.9558 - dense_2_loss: 0.1608 - dense_3_loss: 0.5684 - dense_4_loss: 0.6635 - dense_5_loss: 0.4381 - dense_6_loss: 0.1209 - dense_7_loss: 0.0040 - val_loss: 1.6304 - val_dense_2_loss: 0.1501 - val_dense_3_loss: 0.4629 - val_dense_4_loss: 0.5302 - val_dense_5_loss: 0.3788 - val_dense_6_loss: 0.1063 - val_dense_7_loss: 0.0021\n",
      "Epoch 8/20\n",
      "135278/135278 [==============================] - 272s - loss: 1.7828 - dense_2_loss: 0.1470 - dense_3_loss: 0.5170 - dense_4_loss: 0.5985 - dense_5_loss: 0.3996 - dense_6_loss: 0.1166 - dense_7_loss: 0.0041 - val_loss: 1.4800 - val_dense_2_loss: 0.1373 - val_dense_3_loss: 0.4166 - val_dense_4_loss: 0.4918 - val_dense_5_loss: 0.3301 - val_dense_6_loss: 0.1020 - val_dense_7_loss: 0.0021\n",
      "Epoch 9/20\n",
      "135278/135278 [==============================] - 277s - loss: 1.6441 - dense_2_loss: 0.1358 - dense_3_loss: 0.4753 - dense_4_loss: 0.5485 - dense_5_loss: 0.3677 - dense_6_loss: 0.1126 - dense_7_loss: 0.0041 - val_loss: 1.3302 - val_dense_2_loss: 0.1108 - val_dense_3_loss: 0.3853 - val_dense_4_loss: 0.4349 - val_dense_5_loss: 0.2997 - val_dense_6_loss: 0.0973 - val_dense_7_loss: 0.0021\n",
      "Epoch 10/20\n",
      "135278/135278 [==============================] - 275s - loss: 1.5394 - dense_2_loss: 0.1263 - dense_3_loss: 0.4484 - dense_4_loss: 0.5086 - dense_5_loss: 0.3429 - dense_6_loss: 0.1089 - dense_7_loss: 0.0042 - val_loss: 1.2313 - val_dense_2_loss: 0.1084 - val_dense_3_loss: 0.3527 - val_dense_4_loss: 0.3990 - val_dense_5_loss: 0.2757 - val_dense_6_loss: 0.0934 - val_dense_7_loss: 0.0021\n",
      "Epoch 11/20\n",
      "135278/135278 [==============================] - 271s - loss: 1.4482 - dense_2_loss: 0.1192 - dense_3_loss: 0.4185 - dense_4_loss: 0.4769 - dense_5_loss: 0.3232 - dense_6_loss: 0.1063 - dense_7_loss: 0.0041 - val_loss: 1.2745 - val_dense_2_loss: 0.1244 - val_dense_3_loss: 0.3590 - val_dense_4_loss: 0.4038 - val_dense_5_loss: 0.2891 - val_dense_6_loss: 0.0962 - val_dense_7_loss: 0.0021\n",
      "Epoch 12/20\n",
      "135278/135278 [==============================] - 657s - loss: 1.3719 - dense_2_loss: 0.1124 - dense_3_loss: 0.3979 - dense_4_loss: 0.4506 - dense_5_loss: 0.3039 - dense_6_loss: 0.1030 - dense_7_loss: 0.0041 - val_loss: 1.1681 - val_dense_2_loss: 0.1074 - val_dense_3_loss: 0.3381 - val_dense_4_loss: 0.3704 - val_dense_5_loss: 0.2594 - val_dense_6_loss: 0.0909 - val_dense_7_loss: 0.0020\n",
      "Epoch 13/20\n",
      "135278/135278 [==============================] - 281s - loss: 1.3105 - dense_2_loss: 0.1079 - dense_3_loss: 0.3807 - dense_4_loss: 0.4273 - dense_5_loss: 0.2884 - dense_6_loss: 0.1020 - dense_7_loss: 0.0042 - val_loss: 1.1110 - val_dense_2_loss: 0.0964 - val_dense_3_loss: 0.3238 - val_dense_4_loss: 0.3536 - val_dense_5_loss: 0.2491 - val_dense_6_loss: 0.0860 - val_dense_7_loss: 0.0021\n",
      "Epoch 14/20\n",
      "135278/135278 [==============================] - 278s - loss: 1.2488 - dense_2_loss: 0.1009 - dense_3_loss: 0.3617 - dense_4_loss: 0.4082 - dense_5_loss: 0.2767 - dense_6_loss: 0.0973 - dense_7_loss: 0.0041 - val_loss: 1.0717 - val_dense_2_loss: 0.1009 - val_dense_3_loss: 0.3053 - val_dense_4_loss: 0.3404 - val_dense_5_loss: 0.2376 - val_dense_6_loss: 0.0853 - val_dense_7_loss: 0.0021\n",
      "Epoch 15/20\n",
      "135278/135278 [==============================] - 298s - loss: 1.2069 - dense_2_loss: 0.0984 - dense_3_loss: 0.3493 - dense_4_loss: 0.3933 - dense_5_loss: 0.2671 - dense_6_loss: 0.0947 - dense_7_loss: 0.0042 - val_loss: 1.0054 - val_dense_2_loss: 0.0898 - val_dense_3_loss: 0.2816 - val_dense_4_loss: 0.3230 - val_dense_5_loss: 0.2250 - val_dense_6_loss: 0.0838 - val_dense_7_loss: 0.0021\n",
      "Epoch 16/20\n",
      "135278/135278 [==============================] - 279s - loss: 1.1647 - dense_2_loss: 0.0953 - dense_3_loss: 0.3409 - dense_4_loss: 0.3732 - dense_5_loss: 0.2567 - dense_6_loss: 0.0943 - dense_7_loss: 0.0042 - val_loss: 0.9663 - val_dense_2_loss: 0.0899 - val_dense_3_loss: 0.2729 - val_dense_4_loss: 0.3095 - val_dense_5_loss: 0.2135 - val_dense_6_loss: 0.0784 - val_dense_7_loss: 0.0021\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 289s - loss: 1.1282 - dense_2_loss: 0.0929 - dense_3_loss: 0.3272 - dense_4_loss: 0.3650 - dense_5_loss: 0.2473 - dense_6_loss: 0.0917 - dense_7_loss: 0.0042 - val_loss: 0.9638 - val_dense_2_loss: 0.0862 - val_dense_3_loss: 0.2812 - val_dense_4_loss: 0.3032 - val_dense_5_loss: 0.2116 - val_dense_6_loss: 0.0796 - val_dense_7_loss: 0.0021ss: 0.0910 - dense_7_loss: 1.5 - ETA: 271s - loss: 1.1062 -  - ETA: 261s - loss: 1.1377 - dense_2_loss: 0.0871 - dense_3_loss: 0.3293 - dense_4_loss: 0.3763 - dense_5_loss: 0.2477 - d - ETA: 258s - loss: 1.1429 - dense_2_loss: 0.0893 - dense_3_loss: 0.3330  - ETA: 252s - loss: 1.1470 - dense_2_loss: 0.0909 - dense_3_loss: 0.3358 - dense_4_loss: 0.3749 - dense_5_loss: 0.246 - ETA: 249s - loss: 1.1417 - dense_2_loss: 0.0887 - dense_3_loss: 0.3361 - dense_4_loss: 0.3719 - dense_5_loss: 0.2459 - dense_6_loss: 0.093 - ETA: 247s - loss: 1.1430 - dense_2_loss: 0.0888 - dense_3_loss: 0.332 - ETA: 241s - loss: 1.1384 - dense_2_loss: 0.0878 - dense_3_loss: 0.3340 - dense_4_loss: 0.3706 - dense_5_loss: 0.2471 - dense_6_loss - ETA: 239s - loss: 1.1284 - dense_2_loss: 0.0869 - dense_3_loss: 0.3309 - dense_4_loss: 0.3671 - dense_5_loss: 0.2459 - dense_6_loss: 0. - ETA: 237s - loss: 1.1283 - dense_2_loss: 0.0866 - dense_3_loss: 0.3305 - dense_4_loss: 0.3668 - dense_5_loss: 0.2466 - dense_6_loss: - ETA: 235s - loss: 1.1275 - dense_2_loss: 0.0873 - dense_3_loss: 0.3307 - dense_4_loss: 0.3666 - dense_5_l - ETA: 231s - loss: 1.1298 - dense_2_loss: 0.0876 - dense_3_loss: 0.3314 - dense_4_loss: 0.3674 - dense_5_loss: 0.2457 - de - ETA: 229s - loss: 1.1274 - dense_2_loss: 0.0879 - dense_3_loss: 0.3300 - dense_4_loss: 0.3669 - dense_5_loss: 0.2452 - dense_6_loss: 0.0932 - den - ETA: 227s - loss: 1.1257 - dense_2_loss: 0.0876 - dense_3_loss: 0.3301 - dense_4_loss: 0.3671 - dense_5_loss: 0.2437 - dense_6_loss: 0.0931 - dense_7 - ETA: 227s - loss: 1.1229 - dense_2_loss: 0.0870 - dense_3_loss: 0.3298 - dense_4_loss: 0.3654 - dense_5_loss: 0.2442 - dense_6_loss: - ETA: 225s - loss: 1.1224 - dense_2_loss: 0.0873 - dense_3_loss: 0.3290 - dense_4_ - ETA: 219s - loss: 1.1159 - dense_2_loss: 0.0866 - dense_3_loss: 0.3264 - dense_4_loss: 0.36 - ETA: 158s - loss: 1.1206 - dense_2_loss: 0.0895 - dense_3_loss: 0.3257 - dense_4_loss: 0.3645 - dense_5_loss: 0 - ETA: 154s - loss: 1.1235 - dense_2_loss: 0.0897 -  - ETA: 147s - loss: 1.1234 - dense_2_loss: 0.0894 - dense_3_loss: 0.3263 - dense_4_loss: 0.3657 - dense_5_loss: 0.2454 - dense_6_loss: 0.0931 - d - ETA: 146s - loss: 1.1222 - dense_2_loss: 0.0894 - dense_3_loss: 0.3261 - dense_4_loss: 0.3654 - dense_5_loss: 0.2449 - dense_6_loss: 0.0929 - dense_7_loss: 0. - ETA: 146s - loss: 1.1223 - dense_2_loss: 0.0894 - dense_3_loss: 0.3263 - dense_4_loss: 0.3652 - dense_5_loss: 0.2451 - dense_6_loss: 0.0927 - dense_7_loss:  - ETA: 145s - loss: 1.1226 - dense_2_loss: 0.0894 - dense_3_\n",
      "Epoch 18/20\n",
      "135278/135278 [==============================] - 293s - loss: 1.0931 - dense_2_loss: 0.0903 - dense_3_loss: 0.3176 - dense_4_loss: 0.3522 - dense_5_loss: 0.2388 - dense_6_loss: 0.0899 - dense_7_loss: 0.0042 - val_loss: 0.9847 - val_dense_2_loss: 0.0962 - val_dense_3_loss: 0.2820 - val_dense_4_loss: 0.3072 - val_dense_5_loss: 0.2124 - val_dense_6_loss: 0.0848 - val_dense_7_loss: 0.00210973 - dense_2_loss: 0.0912 - dense_3_loss: 0.3174 - dense_4_loss: 0.3540 - dense_5_loss: 0.2355 - dense_6_loss: 0.09 - ETA: 197s - loss: 1.0975 - dense_2_loss: 0.0910 - dense_3_loss: 0.3175 - dense_4_loss: 0.3539 - dense_5_loss: 0.2356 - dense_6_loss: 0.0946 - dense_7_loss: 0.00 - ETA: 197s - loss: 1.0967 - dense_2_loss: 0.0909 - dense_3_loss: 0.3174 - dense_4_loss: 0.3536 - dense_5_loss: 0.2355 - dense_6_loss: 0.0945 - dense_7_loss: - ETA: 196s - loss: 1.0984 - dense_2_loss: 0.0909 - dense_3_loss: 0.3181 - dense_4_loss: 0.3541 - dense_5_loss: 0.2358 - d - ETA: 193s - loss: 1.0973 - dense_2_loss: 0.0911 - dense_3_loss: 0.3184 - dense_4_loss: 0.3542 - dense_5_loss: 0.2348 - dense_6_loss: 0.0941 - dense_7_loss:  - ETA: 193s - loss: 1.0968 - dense_2_loss: 0.0911 - dense_3_loss: 0.3185 - dense_4_loss: 0.3539 - dense_5_loss: 0.2346 - dense_6_loss: 0.0941 - dense_7_loss - ETA: 192s - loss: 1.0965 - dense_2_loss: 0.091 - ETA: 184s - loss: 1.0994 - dense_2_loss: 0.0914 - dense_3_loss: 0.3196 - dense_4_loss: 0.3538 - dense_5_loss: 0.236 - ETA: 181s - loss: 1.1023 - dense_2_loss: 0.0922 - dense_3_loss: 0.3200 - dense_4_loss: 0.3536 - d - ETA: 177s - loss: 1.1046 - dense_2_loss: 0.0929 - dense_3_loss: 0.3190 - dense_4_loss: 0.3544 - dense_5_loss: 0.2389 - dense_6_loss: 0.0939 - dense_7_loss: - ETA: 176s - loss: 1.1045 - dense_2_loss: 0.0929 - dense_3_loss: 0.3187 - dense_4_loss: 0.3541 - dense_5_loss: 0.2393 - dense_ - ETA: 174s - los - ETA: 164s - loss: 1.0982 - dense_2_loss: 0.0931 - dense_3_loss: 0.3166 - dense_4_loss: 0.3523 - dense_5_loss: 0. - ETA: 161s - loss: 1.1002 - dense_2_loss: 0.0927 - dense_3_loss: 0.3179 - dense_4_loss: 0.3526 - dense_5_loss: 0.2395 - dense_6_loss: 0.0924 - dens - ETA: 160s - loss: 1.0978 - dense_2_loss: 0.0922 - dense_3_loss: 0.3171 - dense_4_loss: 0.3519 - dense_5_loss: 0.23 - ETA: 156s - loss: 1.1017 - dense_2_loss: 0.0924 - dense_3_loss: 0.3186 - dense_4_loss: 0.3531 - - ETA: 130s - loss: 1.1029 - dense_2_loss: 0.0922 - dens - ETA: 122s - loss: 1.1022 - dense_2_loss: 0.0922 - dense_3_loss: 0.3191 - dense_4_loss: 0.3539 - dense_5_loss: 0.2399 - dense_6_loss: 0.0917 - dense_7_loss: 0.0 - ETA: 122s - loss: 1.10 - ETA: 113s - loss: 1.1018 - dense_2_loss: 0.0921 - dense_3_loss: 0.3191 - dense_4_loss: 0.3536 - dense_5_loss: 0.2399 - dens - ETA: 110s - loss: 1.1028 - dense_2_loss: 0.0924 - dense_3_loss: 0.3194 - dense_4_loss: 0.3540 - dense_ - ETA: 106s - loss: 1.1010 - dense_2_loss: 0.0922 - dense_3_loss: 0.3186 - dense_4_loss: 0.3532 - dense_5_loss: 0.2396 - dense_6_loss: 0.0920 - - ETA: 105s - loss: 1.1008 - dense_2_loss: 0.0921 - dense_3_loss: 0.3189 - dense_4_loss: 0.3532 - dense_5_loss: 0.2394 - dense_6_loss: 0.0920 - dense_7_loss - ETA: 104s - loss: 1.1009 - dense_2_loss: 0.0920 - dense_3_loss: 0.3190 - dense_4_loss: 0.3532 - dense_5_loss: 0.2395 - dense_6_ - ETA: 102s - loss: 1.1001 - dense_2_loss: 0.0918 - dense_3_ - ETA: 97s - loss: 1.1005 - d - ETA: 76s - loss: 1.0966 - dense_2_loss: 0.0915 - dense_3_loss: 0.3176 - dense_4_loss: 0.3526 - dense_5_ - ETA: 63s - loss: 1.0946 - dense_2_loss: 0.0905 - dense_3_loss: 0.3178 - dense_4_loss: 0 - ETA: 55s - loss: 1.0934 - dense_2_loss: 0.0904 - dense_3_loss: 0.3173 - dense_4_loss: 0.3520 - dense_5_loss: 0.2387 - dense_6_loss: 0.0902 - dense_7_loss: 0. - ETA: 55s - loss: 1.0935 - dense_2_loss: 0.0903 - dense_3_loss: 0.3173 - ETA: 47s - loss: 1.0948 - dense_2_loss: 0.0905 - dense_3_loss: 0.3180 - dense_4_loss: 0 - ETA: 44s - loss: 1.0949 - dense_2_loss: 0.0906 - dense_ - ETA: 41s - loss: 1.0935 - dense_2_loss: 0.0906 - dense_3_loss: 0.3174 - ETA: 37s -  - ETA: 16s - loss: 1.0913 - dense_2_loss: 0.0900 - dense_3_loss: 0.3166 - dense_4_loss: 0.3521 - dense_5_loss: 0.2384 - dense_6_los - ETA: 15s - loss: 1.0912 - dense_2_los - ETA: 11s - loss: 1.0913 - dense_2_loss: 0.0903 - dense_3_loss: 0.3166 - dense_4_loss: 0.3516 - dense_5_loss: 0.2387 - d - ETA: 9s - loss: 1.0918 - dense_2_loss: 0.0903 - dense_3_loss: 0.3165 - dense_4_loss: 0.3518 - dense_5_loss: 0.2388 - dense_6_loss: 0.0899 - dense_7_los - ETA: 9s - loss: 1.0922 - dense_2_loss: 0.0904 - dense_3_loss: 0.3167 - dense_4_loss: 0.3519 - dense_5_loss: 0.2389 - dense - ETA: 6s - loss: 1.0921 - dense_2_loss: 0.0902 - dense_3_loss:\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 286s - loss: 1.0685 - dense_2_loss: 0.0899 - dense_3_loss: 0.3128 - dense_4_loss: 0.3402 - dense_5_loss: 0.2330 - dense_6_loss: 0.0884 - dense_7_loss: 0.0042 - val_loss: 0.9139 - val_dense_2_loss: 0.0823 - val_dense_3_loss: 0.2685 - val_dense_4_loss: 0.2851 - val_dense_5_loss: 0.2000 - val_dense_6_loss: 0.0757 - val_dense_7_loss: 0.0021_loss: 0.0864 - dense_3_loss: 0.3138 - dense_4_loss: 0.3445 - dense_5_loss: 0.2339 - dense_6_loss: 0. - ETA: 258s - loss: 1.0809 - dense_2_loss: 0.0881 - dense_3_loss: 0.3185 - dense_4_loss: 0.3450 - dense_ - ETA: 254s - loss: 1.0788 - dense_2_loss: 0.0895 - dense_3_loss: 0.3176 - dense_4_loss: 0.3443 - dense_5_loss: 0. - ETA: 251s - loss: 1. - ETA: 242s - loss: 1.0587 - dense_2_loss: 0.0884 - dense_3_loss: 0.3109 - dense_4_loss: 0.3348 - dense_5_loss: 0.2335 - dense_6_loss: 0.0869 - d - ETA: 240s - loss: 1.0546 - dense_2_loss: 0.0882 - dense_3_loss: 0.3110 - dense_4_loss: 0.3321 - dense_5_loss: 0.2332 - dense_6_loss: 0.0860 - dense_7_loss - ETA: 240s - loss: 1.0563 - dense_2_loss: 0.0880 - dense_3_loss: 0.3122 - dense_4_loss: 0.3328 - dense_ - ETA: 36s - loss: 1.0704 - dense_2_loss: 0.0896 - dense_3_lo - ETA: 32s - loss: 1.0709 - dense_2_loss: 0.0896 - de - ETA: 29s - loss: 1.0702 - dense_2_loss: 0.0896 - dense_3_loss: 0.3142 - dense_4_loss: 0.3406 - dense_5_loss: 0.2330 - dense_6_loss: 0.0884 - dense_7_lo - ETA: 28s - loss: 1.0701 - dense_2_loss: 0.0896 - dense_3_loss: 0.3142 - d - ETA: 25s - loss: 1.0708 - dense_2_loss: - ETA: 16s - loss: 1.0692 - dense_2_loss: 0.0895 - dense_3_loss: 0.3134 - dense_4_loss: 0.3403 - dense_5_loss: 0.2334 - dense_6_loss: 0.0885 - dens - ETA: 10s - loss: 1.0692 - dense_2_loss: 0.0897 - dense_3_loss: 0.3135 - dense_4_loss: 0.3401 - dense_5_loss: 0.2331 - dense_6_loss: - ETA: 9s - loss: 1.0686 - dense_2_loss: 0.0897 - dense_3_loss: 0.3131 - dense_4_loss: 0.3401 - dense_5_loss: 0.2331 - dense_6 - ETA: 7s - loss: 1.0690 - dense_2_loss: 0.0898 - dense_3_loss: 0.3130 - dense_4_loss: 0.3404 - dense_5_loss: 0.2330 - dense_6_loss: 0.0886 - dense - ETA: 6s - loss: 1.0695 - dense_2_loss: 0.0899 - dense_3_loss: 0.3130 - dense_4_loss: 0.3407 - dense_5_loss: 0.2332 - dense_6_loss: 0.0885 - den - ETA: 5s - loss: 1.0698 - dense_2_loss: 0.0900 - dense_3_loss: 0.3131 - dense_4_loss: 0.3407 - dense_5_loss: 0.2333 - dense_6_loss: 0.088 - ETA: 3s - loss: 1.0693 - dense_2_loss: 0.0899 - dense_3_loss: 0.3129 - dense_4_loss: 0.3406 - dense_5_loss: 0.2331 - dense_6_loss: 0.0885  - ETA: 2s - loss: 1.0685 - dense_2_loss: 0.0898 - dense_3_loss: 0.3127 - dense_4_loss: 0.3404 - dense_5_loss: 0.2328 - dense_6\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135278/135278 [==============================] - 292s - loss: 1.0369 - dense_2_loss: 0.0848 - dense_3_loss: 0.3016 - dense_4_loss: 0.3329 - dense_5_loss: 0.2271 - dense_6_loss: 0.0862 - dense_7_loss: 0.0042 - val_loss: 0.9194 - val_dense_2_loss: 0.0922 - val_dense_3_loss: 0.2638 - val_dense_4_loss: 0.2803 - val_dense_5_loss: 0.2035 - val_dense_6_loss: 0.0773 - val_dense_7_loss: 0.00210.3432 - dense_4_loss: 0.3069 - dense_5_loss - ETA: 273s - loss: 1.0161 - dense_2_loss: 0.0861 - dense_3_loss: 0.3080 - ETA: 267s - loss: 1.0197 - dense_2_loss: 0.0851 - dense_3_loss: 0.3027 - dense_4_loss: 0.3159 - dense_5_loss: 0.2329 - dense_6 - ETA: 264s - loss: 1.0002 - dense_2_loss: 0.0830 - dense_3_loss: 0.2987 - dense_4_loss: 0. - ETA: 259s - loss: 1.0157 - dense_2_loss: 0.0877 - dense_3_loss: 0.2980 - dense_4_loss: 0.3162 - dense_5_loss: 0.2304 - dense_6_loss: 0.0789 - dense_7_loss - ETA: 259s - loss: 1.0137 - dense_2_loss: 0.0876 - dense_3_loss: 0.2964 - dense_4_loss: 0.3158 - dense_5_loss: 0.2298 - dens - ETA: 256s - loss: 1.0294 - dense_2_loss: 0.0877 - dense_3_loss: 0.3049 - dense_4_loss: 0.3204 - dense_5_loss: 0.2317 - dense_6_loss: 0.0808 - dense_7_loss: 0 - ETA: 256s - loss: 1.0244 - dense_2_loss: 0.0873 - dens - ETA: 248s - loss: 1.0229 - dense_2_loss: 0.0842 - dense_3_loss: 0.2984 - dense_4_loss: 0.3220 - dense_5_loss: 0.2335 - dense_6_loss: 0.0818 - dense_7_loss: 0.0 - ETA: 248s - loss: 1.0239 - dense_2_loss: 0.0851 - dense_3_loss: 0.2980 - dense_4_loss: 0.3217 - dense_5_loss: 0.2334 - dense_6_ - ETA: 246s - loss: 1.0256 - dense_2_loss: 0.0845 - dense_3_loss: 0.2990 - dense_4_loss: 0.3232 - dense_5_loss: 0.2335 - dense_6_loss: 0.0816 - dense_7 - ETA: 245s - loss: 1.0274 - dense_2_loss: 0.0847 - dense_3_loss - ETA: 238s - loss: 1.0283 - dense_2_loss: 0.0870 - dense_3_loss: 0.3012 - dense_4_loss: 0.3225 - dense_5_loss: 0.2283 - dense_6_loss: 0.0822 - de - ETA: 237s - loss: 1.0267 - dense_2_loss: 0.0862 - dense_3_loss: 0.303 - ETA: 220s - loss: 1.0307 - dense_2_loss: 0.0864 - dense_3_loss: 0.3011 - dense_4_loss: 0.3258 - dense_5_loss: 0.227 - ETA: 217s - loss: 1.0325 - dense_2_loss: 0.0866 - dense_3_loss: 0.3019 - dense_4_loss: 0.3271 - dense_5_loss: 0.2280 - dense_6_loss: 0.0822 - dense_ - ETA: 216s - loss: 1.0312 - dense_2_loss: 0.0863 - dense_3_loss: 0.3010 - dense_4_loss: 0.3271 - dense_5_loss: 0 - ETA: 212s - loss: 1.0312 - dense_2_loss: 0.0858 - dense_3_loss: 0.3008 - dense_4_loss: 0.3290 - dense_5_loss: 0.2275 - dense_6_loss: 0.0817 - dense - ETA: 211s - loss: 1.0330 - dense_2_loss: 0.0863 - dense_3_loss: 0.3005 - dense_4_loss: 0.329 - ETA: 207s - loss: 1.0376 - dense_2_loss: 0.0870 - dense_3_loss: 0.3015 - dense_4_loss: 0.3307 - dense_5_loss: 0.2288 - dense_6_loss: 0.082 - ETA: 205s - loss: 1.0370 - dense_2_loss: 0.0870 - dense_3_loss: 0.3005 - dense_4_loss: 0.3300 - dense_5_loss: 0.2290 - dense_6_loss: 0.0838 - dens - ETA: 204s - loss: 1.0381 - dense_2_loss: 0.0869 - dense_3_loss: 0.3008 - dense_4_loss: 0.3306 - dense_5_loss: 0.2289 - dense_6_loss: 0.0844 - dense_7_loss - ETA: 204s - loss: 1.0365 - dense_2_loss: 0.0865 - dense_3_loss: 0.3005 - dense_4_loss: 0.3301 - dense_5_loss: - ETA: 200s - loss: 1.0350 - dense_2_loss: 0.0862 - dense_3_loss: 0.2996 - dense_4_loss: 0.3296 - dense_5_loss: 0.2295 - dense_6_loss: 0.0839  - ETA: 199s - loss: 1.0351 - dense_2_loss: 0.0858 - dense_3_l - ETA: 192s - loss: 1.0385 - dense_2_loss: 0.08 - ETA: 184s - loss: 1.0397 - dense_2_loss: 0.0862 - dense_3_loss: 0.3015 - dense_4_loss: 0.3304 - dense_5_loss: 0.2305 - dense_6_loss: 0.0 - ETA: 182s - loss: 1.0379 - dense_2_loss: 0.0858 - dense_3_loss: 0.3013 - dense_4_loss: 0.3306 - dense_5_loss: 0.2296 - dense_6_loss: 0.08 - ETA: 181s - loss: 1.0398 - dense_2_loss: 0.0861 - dense_3_loss: 0.3019 - dense_4_loss: 0.3316 - dense_5_loss: 0.2294 - dense_6_loss: 0.0852 - den - ETA: 179s - loss: 1.0401 - dense_2_loss: 0.0862 - dense_3_loss: 0.3022 - dense_4_loss: 0.3312 - dense_5_loss: 0.2298 - dense_6_loss: 0.08 - ETA: 178s - loss: 1.0401 - dense_2_loss: 0.0860 - dense_3_loss: 0.3026 - dense_4_loss: 0.3312 - dense_5_loss: 0.2298 - dense_6_loss: 0.0850 - dense_7_loss: 0. - ETA: 177s - loss: 1.0403 - dense_2_loss: 0. - ETA: 170s - loss: 1.0387 - dense_2_loss: 0.0859 - dense_3_loss: 0.3007 - dense_4_loss: 0 - ETA: 165s - loss: 1.0353 - dense_2_loss: 0.0859 - dense_3_loss: 0.3014 - dense_4_loss: 0.329 - ETA: 149 - ETA: 75s - loss: 1.0359 - dense_2_loss: 0.0849 - dense_3_loss: 0.3020 - dense_4_loss: 0.3323 - dense_5_lo - ETA: 73s - loss: 1.0354 - dense_2_l - ETA: 36s - loss: 1.0329 - dense_2_loss: 0.0841 - dense_3_loss: 0.3017 - dense_4_loss: 0.3317 - dense_5_loss: 0.2257 - den - ETA: 35 - ETA: 30s - loss: 1.0335 - dense_2_loss: 0.0844 - dense_3_loss: 0.3014 - dense_4_loss: - ETA: 27s - loss: 1.0348 - dense_2_loss: 0.0846  - ETA: 23s - loss: 1.0341 - dense_2_loss: 0.0846 - dense_3_loss: 0.3011 - dense - ETA: 21s - loss: 1.0350 - dense_2_loss: 0.0849 - dense_3_loss: 0.3012 - dense_4_loss - ETA: 5s - loss: 1.0380 - dense_2_loss: 0.0852 - dense_3_loss: 0.3018 - dense_4_loss: 0.3330 - dense_5_loss: 0.2274 - dense_6_loss: 0.0863 - dense_7_loss: 0 - ETA: 4s - loss: 1.0380 - dense_2_loss: 0.0852 - dense_3_loss: 0.3019 - dense_4_loss: 0.3331 - dense_5_loss: 0.2273 - dense_6_loss: 0.0862 -  - ETA: 3s - loss: 1.0381 - dense_2_loss: 0.0852 - dense_3_loss: 0.3020 - dense_4_loss: 0.3330 - dense_5_loss: 0.2273 - dense_6_loss: 0.0863 - dense_ - ETA: 2s - loss: 1.0379 - dense_2_loss: 0.0850 - dense_3_loss: 0.3019 - dense_4_loss: 0.3331 - dense_5_loss: 0.2272 - dense_6_loss: 0.0863 - dense_7_loss - ETA: 2s - loss: 1.0373 - dense_2_loss: 0.0850 - dense_3_loss: 0.3018 - dense_4_loss: 0.3329 - dense_5_loss: 0.2272 - dense_6_los\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "result = model.fit(images, [labels[:,:7], labels[:,7:18], labels[:,18:29], labels[:,29:40], labels[:,40:51], labels[:,51:62]], 32, 20, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75839770073648283"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "score = model.predict(test_images)\n",
    "\n",
    "score = np.concatenate(score, axis=1)\n",
    "#round score to get actual prediction instead of probability\n",
    "roundedScore = np.zeros(score.shape, dtype=\"int32\")\n",
    "#choose threshold\n",
    "roundedScore[score > 0.5] = 1\n",
    "\n",
    "#rounded acc (exactly match)\n",
    "accuracy_score(test_labels, roundedScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
